


@conference {3492,
	title = {On the Use of Note Onsets for Improved Lyrics-to-audio Alignment in Turkish Makam Music},
	booktitle = {17th International Society for Music Information Retrieval Conference (ISMIR 2016) },
	year = {2016},
	month = {05/08/2016},
	address = {New York, USA},
	abstract = {Lyrics-to-audio alignment aims to automatically match
given lyrics and musical audio. In this work we extend a
state of the art approach for lyrics-to-audio alignment with
information about note onsets. In particular, we consider
the fact that transition to next lyrics syllable usually implies
transition to a new musical note. To this end we formulate
rules that guide the transition between consecutive
phonemes when a note onset is present. These rules are incorporated
into the transition matrix of a variable-time hidden
Markov model (VTHMM) phonetic recognizer based
on MFCCs. An estimated melodic contour is input to
an automatic note transcription algorithm, from which the
note onsets are derived. The proposed approach is evaluated
on 12 a cappella audio recordings of Turkish Makam
music using a phrase-level accuracy measure. Evaluation
of the alignment is also presented on a polyphonic version
of the dataset in order to assess how degradation in the extracted
onsets affects performance. Results show that the
proposed model outperforms a baseline approach unaware
of onset transition rules. To the best of our knowledge, this
is the one of the first approaches tackling lyrics tracking,
which combines timbral features with a melodic feature in
the alignment process itself.},
	author = {Georgi Dzhambazov and Ajay Srinivasamurthy and Sertan {\c S}ent{\"u}rk and Xavier Serra}
}
@conference {3565,
	title = {Singing Voice Separation by Harmonic Modeling},
	booktitle = { Music Information Retrieval Evaluation eXchange (MIREX)},
	year = {2016},
	author = {Georgi Dzhambazov and Xavier Serra}
}

@conference {3517,
	title = {Automatic Alignment of Long Syllables In A cappella Beijing Opera},
	booktitle = {6th International Workshop on Folk Music Analysis (FMA 2016)},
	year = {2016},
	month = {15/06/2016},
	pages = {88-91},
	address = {Dublin, Ireland},
	abstract = {In this study we propose how to modify a standard approach for text-to-speech alignment to apply in the case of alignment of lyrics and singing voice. We model phoneme durations by means of a duration-explicit hidden Markov model (DHMM) phonetic recognizer based on MFCCs. The phoneme durations are empirically set in a probabilistic way, based on prior knowledge about the lyrics structure and metric principles, specific for the Beijing opera music tradition. Phoneme models are GMMs trained directly on a small corpus of annotated singing voice. The alignment is evaluated on a cappella material from Beijing opera, which is characterized by its particularly long syllable durations. Results show that the incorporation of music-specific knowledge results in a very high alignment accuracy, outperforming significantly a baseline HMM-based approach.},
	url = {http://arrow.dit.ie/fema/1/},
	author = {Georgi Dzhambazov and Yile Yang and Rafael Caro Repetto and Xavier Serra}
}



@conference {3266,
	title = {Modeling of Phoneme Durations for Alignment between Polyphonic Audio and Lyrics},
	booktitle = {Sound and Music Computing Conference 2015},
	year = {2015},
	address = {Maynooth, Ireland},
	abstract = {In this work we propose how to modify a standard scheme for text-to-speech alignment for the alignment of lyrics and singing voice. To this end we model the duration of phonemes specific for the case of singing. We rely on a duration-explicit hidden Markov model (DHMM) phonetic recognizer based on mel frequency cepstral coefficients (MFCCs), which are extracted in a way robust to background instrumental sounds. The proposed approach is tested on polyphonic audio from the classical Turkish music tradition in two settings: with and without modeling phoneme durations. Phoneme durations are inferred from sheet music. In order to assess the impact of the polyphonic setting, alignment is evaluated as well on an acapella dataset, compiled especially for this study. We show that the explicit modeling of phoneme durations improves alignment accuracy by absolute 10 percent on the level of lyrics lines (phrases) and performs on par with state-of-the-art aligners for other languages.},
	author = {Georgi Dzhambazov and Xavier Serra}
}

@conference {2965,
	title = {Automatic lyrics-to-audio alignment in classical Turkish music},
	booktitle = {4th International Workshop on Folk Music Analysis},
	year = {2014},
	month = {12/06/2014},
	pages = {61-64},
	address = {Istanbul, Turkey},
	abstract = {We apply a lyrics-to-audio alignment state-of-the-art approach
to polyphonic pieces from classical Turkish repertoire. A phonetic
recognizer is employed, whereby each phoneme is assigned
a hidden Markov model (HMM). Initially trained on
speech, the models are adapted on singing voice to match
the acoustic characteristics of the test dataset. Being the
first study on lyrics-to-audio alignment applied on Turkish
music, it could serve as a baseline for singing material
with similar musical characteristics. As part of this work
a dataset of recordings from the classical music tradition is
compiled. Experiments, conducted separately for male and
female singers, show that female singing is aligned more
accurately.},
	keywords = {alignment, hmm, lyrics, phonemes, singing voice, Turkish, Viterbi},
	author = {Georgi Dzhambazov and Sertan {\c S}ent{\"u}rk and Xavier Serra}
}


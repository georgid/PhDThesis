#LyX 2.2 created this file. For more info see http://www.lyx.org/
\lyxformat 508
\begin_document
\begin_header
\save_transient_properties true
\origin unavailable
\textclass memoir
\begin_preamble
\definecolor{BLACK}{gray}{0}
\setsecnumdepth{subsection}
\usepackage[automake]{glossaries}
\makeglossaries

%\newacronym{cd}{CD}{compact disk}

\newglossaryentry{LAA}{type=\acronymtype, name={LAA}, description={Lyrics-to-Audio Alignment}, first={Lyrics-to-Audio Alignment (LAA)} }
\newglossaryentry{MIR}{type=\acronymtype, name={MIR}, description={Music Information Retrieval}, first={Music Information Retrieval (MIR)} }
\newglossaryentry{OTMM}{type=\acronymtype, name={OTMM}, description={Ottoman Turkish Makam Music}, first={Ottoman Turkish Makam Music (OTMM)} }
\newglossaryentry{MLP}{type=\acronymtype, name={MLP}, description={Multi-Layer Perceptron}, first={Multi-Layer Perceptron (MLP)} }
\newglossaryentry{GMM}{type=\acronymtype, name={GMM}, description={Gaussian Mixture Model}, first={Gaussian Mixture Model (GMM)} }
\newglossaryentry{HMM}{type=\acronymtype, name={HMM}, description={Hidden Markov Model}, first={Hidden Markov Model (HMM)} }
\newglossaryentry{DHMM}{type=\acronymtype, name={DHMM}, description={Duration-explicit Hidden Markov Model}, first={Duration-explicit Hidden Markov Model (DHMM)} }
\newglossaryentry{DBN}{type=\acronymtype, name={DBN}, description={Dynamic Bayesian Network}, first={Dynamic Bayesian Network (DBN)} }
\newglossaryentry{VAD}{type=\acronymtype, name={VAD}, description={Voice Activity Detection}, first={Voice Activity Detection (VAD)} }
\newglossaryentry{MFCC}{type=\acronymtype, name={MFCC}, description={Mel Frequency Cepstral Coefficients}, first={Mel Frequency Cepstral Coefficients (MFCC)} }


%%%%%%%%%% Document begins %%%%%%%%%%


%\usepackage[nodoi]{apacite}
%\bibliographystyle{myapacite} 

%\definecolor{LinkColor}{rgb}{0, 0, 0.3} 
%\definecolor{ExtLinkColor}{rgb}{0, 0.3, 0}

%\usepackage[table,xcdraw]{xcolor}
%\usepackage{colortbl} % For some nice looking tables, assumes xcolor is already loaded
\end_preamble
\options noend,nofillcomment,figure, a4paper
\use_default_options false
\maintain_unincluded_children true
\language english
\language_package default
\inputencoding auto
\fontencoding global
\font_roman "lmodern" "default"
\font_sans "helvet" "Helvetica"
\font_typewriter "tgcursor" "default"
\font_math "auto" "auto"
\font_default_family default
\use_non_tex_fonts true
\font_sc false
\font_osf false
\font_sf_scale 100 100
\font_tt_scale 100 100
\graphics default
\default_output_format default
\output_sync 0
\output_sync_macro "\synctex=1"
\bibtex_command default
\index_command default
\paperfontsize 11
\spacing single
\use_hyperref true
\pdf_title "Knowledge-based probabilistic modeling for tracking lyrics in music audio signals"
\pdf_author "Georgi Dzhambazov"
\pdf_subject "PhD thesis"
\pdf_bookmarks true
\pdf_bookmarksnumbered false
\pdf_bookmarksopen false
\pdf_bookmarksopenlevel 1
\pdf_breaklinks true
\pdf_pdfborder true
\pdf_colorlinks true
\pdf_backref page
\pdf_pdfusetitle false
\pdf_quoted_options "citecolor=blue,linkcolor=blue"
\papersize default
\use_geometry false
\use_package amsmath 1
\use_package amssymb 1
\use_package cancel 1
\use_package esint 1
\use_package mathdots 1
\use_package mathtools 1
\use_package mhchem 1
\use_package stackrel 1
\use_package stmaryrd 1
\use_package undertilde 1
\cite_engine natbib
\cite_engine_type authoryear
\biblio_style plainnat
\use_bibtopic false
\use_indices false
\paperorientation portrait
\suppress_date false
\justification true
\use_refstyle 0
\boxbgcolor #283d86
\index Index
\shortcut idx
\color #008000
\end_index
\leftmargin 20page%
\rightmargin 20page%
\secnumdepth 3
\tocdepth 2
\paragraph_separation skip
\defskip smallskip
\quotes_language english
\papercolumns 1
\papersides 1
\paperpagestyle default
\listings_params "basicstyle={\ttfamily\small},captionpos=b"
\tracking_changes false
\output_changes false
\html_math_output 0
\html_css_as_file 0
\html_be_strict false
\end_header

\begin_body

\begin_layout Standard
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
frontmatter
\end_layout

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Note Note
status open

\begin_layout Plain Layout
Edit entrega/a4opof.odt and generate pdf
\end_layout

\end_inset


\end_layout

\begin_layout Standard
\begin_inset External
	template PDFPages
	filename entrega/a4opof.pdf
	lyxscale 20
	extra LaTeX "pages=1"

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Newpage newpage
\end_inset


\end_layout

\begin_layout Standard
\begin_inset CommandInset include
LatexCommand include
filename "licencia.lyx"

\end_inset

 
\begin_inset ERT
status collapsed

\begin_layout Plain Layout

% ---------------
\end_layout

\end_inset


\end_layout

\begin_layout Standard
\begin_inset ERT
status collapsed

\begin_layout Plain Layout


\backslash
cleartorecto
\end_layout

\end_inset

 
\begin_inset ERT
status collapsed

\begin_layout Plain Layout


\backslash
setlength{
\backslash
parindent}{0in}
\end_layout

\end_inset

 
\begin_inset ERT
status collapsed

\begin_layout Plain Layout


\backslash
nonzeroparskip
\end_layout

\end_inset


\end_layout

\begin_layout Standard
\begin_inset ERT
status collapsed

\begin_layout Plain Layout

% Uncomment following two lines for getting a tribunal page.
\end_layout

\begin_layout Plain Layout

\end_layout

\end_inset


\begin_inset CommandInset include
LatexCommand include
filename "tribunal.lyx"

\end_inset

 
\begin_inset ERT
status collapsed

\begin_layout Plain Layout


\backslash
cleartorecto
\end_layout

\end_inset

 
\begin_inset ERT
status collapsed

\begin_layout Plain Layout

% ---------------
\end_layout

\end_inset


\end_layout

\begin_layout Standard
\begin_inset CommandInset include
LatexCommand include
filename "dedication.lyx"

\end_inset


\end_layout

\begin_layout Standard
\begin_inset ERT
status collapsed

\begin_layout Plain Layout


\backslash
cleartorecto
\end_layout

\end_inset

 
\begin_inset CommandInset include
LatexCommand include
filename "preface.lyx"

\end_inset


\begin_inset ERT
status collapsed

\begin_layout Plain Layout


\backslash
cleartorecto
\end_layout

\end_inset

 
\begin_inset CommandInset include
LatexCommand include
filename "acknowledgements.lyx"

\end_inset

 
\begin_inset ERT
status collapsed

\begin_layout Plain Layout


\backslash
cleartorecto
\end_layout

\end_inset

 
\end_layout

\begin_layout Standard
\begin_inset Note Note
status collapsed

\begin_layout Plain Layout
\begin_inset Box Frameless
position "t"
hor_pos "c"
has_inner_box 1
inner_pos "t"
use_parbox 0
use_makebox 0
width "100col%"
special "none"
height "1in"
height_special "totalheight"
thickness "0.4pt"
separation "3pt"
shadowsize "4pt"
framecolor "black"
backgroundcolor "none"
status collapsed

\begin_layout Plain Layout

\end_layout

\end_inset


\begin_inset VSpace vfill
\end_inset


\end_layout

\begin_layout Plain Layout
© 2017 Georgi Dzhambazov
\begin_inset VSpace bigskip
\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Graphics
	filename entrega/cc.svg

\end_inset

 
\begin_inset Graphics
	filename entrega/by.svg

\end_inset

 
\begin_inset Graphics
	filename entrega/sa.svg

\end_inset


\begin_inset VSpace bigskip
\end_inset


\end_layout

\begin_layout Plain Layout
This work is licensed under the Creative Commons Attribution-ShareAlike
 4.0 International License.
 To view a copy of this license, visit 
\begin_inset CommandInset href
LatexCommand href
name "http://creativecommons.org/licenses/by-sa/4.0/"
target "http://creativecommons.org/licenses/by-sa/4.0/"

\end_inset

.
\end_layout

\begin_layout Plain Layout
\begin_inset Newpage newpage
\end_inset


\begin_inset Separator latexpar
\end_inset


\end_layout

\begin_layout Quotation
\align right

\emph on
\begin_inset Box Frameless
position "t"
hor_pos "c"
has_inner_box 1
inner_pos "t"
use_parbox 0
use_makebox 0
width "100col%"
special "none"
height "1in"
height_special "totalheight"
thickness "0.4pt"
separation "3pt"
shadowsize "4pt"
framecolor "black"
backgroundcolor "none"
status open

\begin_layout Plain Layout

\end_layout

\end_inset


\begin_inset Newline newline
\end_inset


\begin_inset Newline newline
\end_inset


\begin_inset Newline newline
\end_inset


\begin_inset Newline newline
\end_inset


\begin_inset Newline newline
\end_inset


\begin_inset Newline newline
\end_inset


\begin_inset Newline newline
\end_inset


\begin_inset Newline newline
\end_inset


\begin_inset Newline newline
\end_inset


\begin_inset Newline newline
\end_inset


\begin_inset Newline newline
\end_inset


\begin_inset Newline newline
\end_inset

Dedicatòria.
\end_layout

\begin_layout Chapter*
Acknowledgements
\end_layout

\begin_layout Plain Layout
\begin_inset Newpage newpage
\end_inset


\begin_inset Box Frameless
position "t"
hor_pos "c"
has_inner_box 1
inner_pos "t"
use_parbox 0
use_makebox 0
width "100col%"
special "none"
height "1in"
height_special "totalheight"
thickness "0.4pt"
separation "3pt"
shadowsize "4pt"
framecolor "black"
backgroundcolor "none"
status open

\begin_layout Plain Layout

\end_layout

\end_inset


\begin_inset VSpace vfill
\end_inset


\end_layout

\begin_layout Plain Layout
This work is partially supported by [add your funding grants here]
\end_layout

\end_inset


\end_layout

\begin_layout Chapter*
Abstract
\end_layout

\begin_layout Standard
This thesis proposes specific signal processing and machine learning methods
 for automatically aligning the lyrics of a song to its corresponding audio
 recording.
 The research carried out falls in the broader field of music information
 retrieval (MIR) and in this respect, we aim at improving some existing
 state-of-the-art methods, by introducing domain-specific knowledge.
\end_layout

\begin_layout Standard
The goal of this work is to devise models capable of tracking in the music
 audio signal the sequential aspect of one particular element of lyrics
 – the phonemes.
 Music can be understood as comprising different facets, one of which is
 lyrics.
 The models we build take into account the 
\emph on
complementary context
\emph default
 that exists around lyrics, which is any musical facet complementary to
 lyrics.
 The facets used in this thesis include the structure of the music composition,
 temporal structure of a lyrics line, the structure of the metrical cycle.
 From this perspective, we analyse not only the low-level acoustic characteristi
cs, representing the timbre of the phonemes, but also higher-level characteristi
cs, in which the complementary context manifests.
 We propose specific probabilistic models to represent how the transitions
 between consecutive sung phonemes are conditioned by different facets of
 complementary context.
\end_layout

\begin_layout Standard
The complementary context, which we address, unfolds in time according to
 principles that are particular of a music tradition.
 To capture these, we created corpora and datasets for two music traditions,
 which have a rich set of such principles: Ottoman Turkish makam and Beijing
 opera.
 The datasets and the corpora comprise different data types: audio recordings,
 music scores, and metadata.
 From this perspective, the proposed models can take advantage both of the
 data and the music-domain knowledge of particular musical styles to improve
 existing baseline approaches.
\end_layout

\begin_layout Standard
As a baseline, we choose a phonetic recognizer based on hidden Markov models
 (HMM): a widely-used method for tracking phonemes both in singing and speech
 processing problems.
 We present refinements in the typical steps of existing phonetic recognizer
 approaches, tailored towards the characteristics of the studied music tradition
s.
 On top of the refined baseline, we devise probabilistic models, based on
 dynamic Bayesian networks (DBN) that represent the relation of phoneme
 transitions to its complementary context.
 Two separate models are built for two granularities of complementary context:
 the temporal structure of a lyrics line (higher-level) and the structure
 of the metrical cycle (finer-level).
 In one model we exploit the fact the syllable durations depend on their
 position within a lyrics line.
 Information about the expected durations is obtained from the score, as
 well as from music-specific knowledge.
 Then in another model, we analyse how vocal note onsets, estimated from
 audio recordings, influence the transitions between consecutive vowels
 and consonants.
 We also propose how to detect the time positions of sung note onsets by
 tracking simultaneously the positions in the metrical cycle (i.e.
 metrical accents).
\end_layout

\begin_layout Standard
In order to evaluate the potential of the proposed models, we use lyrics-to-audi
o alignment as a concrete task.
 Each model improves the alignment accuracy, compared to the baseline, which
 is based solely on the acoustics of the phonetic timbre.
 This validates our hypothesis that knowledge of complementary context is
 an important stepping stone for computationally tracking lyrics, especially
 in the challenging case of singing with instrumental accompaniment.
\end_layout

\begin_layout Standard
The outcomes of this study are not only theoretic methods and data, but
 also specific software tools that have been integrated into Dunya — a suite
 of tools, built in the context of CompMusic, a project for advancing the
 computational analysis of the world's music.
 With this application, we have also shown that the developed methods are
 useful not only for tracking lyrics, but also for other use cases, such
 as enriched music listening and appreciation, and for educational purposes.
\end_layout

\begin_layout Chapter*
Resum
\end_layout

\begin_layout Standard
La tesi aquí presentada proposa metodologies d’aprenentatge automàtic i
 processament de senyal per alinear automàticament el text d’una cançó amb
 el seu corresponent enregistrament d’àudio.
 La recerca duta a terme s’engloba en l’ampli camp de l’extracció d’informació
 musical (Music Information Retrieval o MIR).
 Dins aquest context la tesi pretén millorar algunes de les metodologies
 d’última generació del camp introduint coneixement específic de l’àmbit.
\end_layout

\begin_layout Standard
L’objectiu d’aquest treball és dissenyar models que siguin capaços de detectar
 en la senyal d’àudio l’aspecte seqüencial d’un element particular dels
 textos musicals; els fonemes.
\end_layout

\begin_layout Standard
Podem entendre la música com la composició de diversos elements entre els
 quals podem trobar el text.
 Els models que construïm tenen en compte el context complementari del text.
 El context són tots aquells aspectes musicals que complementen el text,
 dels quals hem utilitzat en aquest tesi: la estructura de la composició
 musical, la estructura de les frases melòdiques i els accents rítmics.
 Des d’aquesta prespectiva analitzem no només les característiques acústiques
 de baix nivell, que representen el timbre musical dels fonemes, sinó també
 les característiques d’alt nivell en les quals es fa patent el context
 complementari.
 En aquest treball proposem models probabilístics específics que representen
 com les transicions entre fonemes consecutius de veu cantanda es veuen
 afectats per diversos aspectes del context complementari.
\end_layout

\begin_layout Standard
El context complementari que tractem aquí es desenvolupa en el temps en
 funció de les característiques particulars de cada tradició musical.
 Per tal de modelar aquestes característiques hem creat corpus i conjunts
 de dades de dues tradicions musicals que presenten una gran riquesa en
 aquest aspectes; la música de l’opera de Beijing i la música makam turc-otomana.
 Les dades són de diversos tipus; enregistraments d’àudio, partitures musicals
 i metadades.
 Des d’aquesta prespectiva els models proposats poden aprofitar-se tant
 de les dades en si mateixes com del coneixement específic de la tradició
 musical per a millorar els resultats de referència actuals.
\end_layout

\begin_layout Standard
Com a resultat de referència prenem un reconeixedor de fonemes basat en
 models ocults de Markov (Hidden Markov Models o HMM), una metodologia abastamen
t emprada per a detectar fonemes tant en la veu cantada com en la parlada.
 Presentem millores en els processos comuns dels reconeixedors de fonemes
 actuals, ajustant-los a les característiques de les tradicions musicals
 estudiades.
 A més de millorar els resultats de referència també dissenyem models probabilis
tics basats en xarxes dinàmiques de Bayes (Dynamic Bayesian Networks o DBN)
 que respresenten la relació entre la transició dels fonemes i el context
 complementari.
 Hem creat dos models diferents per dos aspectes del context complementari;
 la estructura de la frase melòdica (alt nivell) i la estructura mètrica
 (nivell subtil).
 En un dels models explotem el fet que la duració de les síl·labes depén
 de la seva posició en la frase melòdica.
 Obtenim aquesta informació sobre les frases musical de la partitura i del
 coneixement específic de la tradició musical.
 En l’altre model analitzem com els atacs de les notes vocals, estimats
 directament dels enregistraments d’àudio, influencien les transicions entre
 vocals i consonants consecutives.
 A més també proposem com detectar les posicions temporals dels atacs de
 les notes en les frases melòdiques a base de localitzar simultàniament
 els accents en un cicle mètric musical.
 
\end_layout

\begin_layout Standard
Per tal d’evaluar el potencial dels mètodes proposats utlitzem la tasca
 específica d’alineament de text amb àudio.
 Cada model proposat millora la precisió de l’alineament en comparació als
 resultats de referència, que es basen exclusivament en les característiques
 acústiques tímbriques dels fonemes.
 D’aquesta manera validem la nostra hipòtesi de que el coneixement del context
 complementari ajuda a la detecció automàtica de text musical, especialment
 en el cas de veu cantada amb acompanyament instrumental.
 
\end_layout

\begin_layout Standard
Els resultats d’aquest treball no consisteixen només en metodologies teòriques
 i dades, sinó també en eines programàtiques específiques que han sigut
 integrades a Dunya, un paquet d’eines creat en el context del projecte
 de recerca CompMusic, l’objectiu del qual és promoure l’anàlisi computacional
 de les músiques del món.
 Gràcies a aquestes eines demostrem també que les metodologies desenvolupades
 es poden fer servir per a altres aplicacions en el context de la educació
 musical o la escolta musical enriquida.
 
\end_layout

\begin_layout Standard
\begin_inset VSpace defskip
\end_inset


\end_layout

\begin_layout Standard

\emph on
(Translated from English by Oriol Roman
\emph default
í
\emph on
 Picas)
\end_layout

\begin_layout Chapter*
Resumen
\end_layout

\begin_layout Standard
Esta tesis propone metodologías específicas de procesamiento de señales
 y aprendizaje automático para alinear de manera automática la letra de
 una canción a su correspondiente grabación de audio.
 La investigación llevada a cabo recae en el campo más amplio de la recuperación
 de información musical (MIR), y por lo tanto, pretendemos con ella mejorar
 algunas de las metodologías más avanzadas de la actualidad, introduciendo
 conocimiento específico del dominio.
\end_layout

\begin_layout Standard
El objetivo de este trabajo es diseñar modelos capaces de rastrear en la
 señal de audio musical el aspecto secuencial de un elemento particular
 de la letra, los fonemas.
 Se puede entender que la música comprende diferentes facetas, una de las
 cuales es la letra.
 Los modelos que construimos tienen en cuenta el contexto complementario
 que existe alrededor de la letra, que es cualquier faceta musical complementari
a a las letras.
 Las facetas utilizadas en esta tesis incluyen la estructura de la composición
 musical, la estructura temporal de un enunciado de la letra, la estructura
 métrica.
 Desde esta perspectiva, analizamos no sólo las características acústicas
 de bajo nivel, que representan el timbre de los fonemas, sino también las
 características de alto nivel, en las que se manifiesta el contexto complementa
rio.
 Proponemos modelos probabilísticos específicos para representar cómo las
 transiciones entre fonemas cantados consecutivamente están condicionadas
 por diferentes facetas del contexto complementario.
\end_layout

\begin_layout Standard
El contexto complementario, al cual abordamos, se despliega en el tiempo
 según principios propios de una tradición musical.
 Para capturar estos principios, hemos creado corpus y conjuntos de datos
 para dos tradiciones musicales, dichas que tienen un rico conjunto de tales
 principios: makam turco otomano y ópera de Beijing.
 Los conjuntos de datos y los corpus comprenden diferentes tipos de datos:
 grabaciones de audio, partituras y metadatos.
 Desde esta perspectiva, los modelos propuestos pueden aprovechar tanto
 los datos como el conocimiento del dominio de la música de determinados
 estilos musicales para mejorar los enfoques existentes usados como referencia.
 
\end_layout

\begin_layout Standard
Como punto de partida, elegimos un reconocedor fonético basado en modelos
 ocultos de Markov (HMM): una metodología ampliamente utilizada para el
 rastreo de fonemas tanto en el canto como en los problemas de procesamiento
 del habla.
 Presentamos mejoras en los pasos típicos de los enfoques de reconocimiento
 fonético existentes, dirigidos hacia las características de las tradiciones
 musicales estudiadas.
 Además de los puntos de partida mejorados, usamos modelos probabilísticos
 basados en redes bayesianas dinámicas (DBN) que representan la relación
 de las transiciones de fonemas con su contexto complementario.
 Se construyen dos modelos independientes para dos granularidades de contexto
 complementario: la estructura temporal de un enunciado de la letra (alto
 nivel) y la estructura del ciclo métrico (nivel más fino).
 En un modelo explotamos el hecho de que las duraciones de las sílabas dependen
 de su posición dentro de un enunciado de la letra.
 La información sobre las duraciones esperadas se obtiene de la partitura,
 así como de conocimientos específicos de la música.
 Luego, en otro modelo, analizamos cómo los onsets de notas vocales, estimados
 a partir de grabaciones de audio, influyen en las transiciones entre vocales
 consecutivas y consonantes.
 También proponemos cómo detectar las posiciones de tiempo de los onsets
 de nota cantada mediante el rastreo simultáneo de las posiciones en el
 ciclo métrico (es decir, acentos métricos).
\end_layout

\begin_layout Standard
Con el fin de evaluar el potencial de los modelos propuestos, utilizamos
 la alineación de letra a grabación de audio como una tarea concreta.
 Cada modelo mejora la precisión de la alineación, en comparación con el
 modelo de referencia inicial, que se basa únicamente en la acústica del
 timbre fonético.
 Esto valida nuestra hipótesis de que el conocimiento del contexto complementari
o es un factor importante para el seguimiento computacional de las letras,
 especialmente en el desafiante caso de cantar junto a un acompañamiento
 instrumental.
\end_layout

\begin_layout Standard
Los resultados de este estudio no son sólo metodologías teóricas y datos,
 sino también herramientas de software específicas que se han integrado
 en Dunya — un conjunto de herramientas, construido en el contexto de CompMusic,
 un proyecto para avanzar el análisis computacional de la música del mundo.
 Con esta aplicación, también hemos demostrado que las metodologías desarrollada
s son útiles no sólo para el seguimiento de letras, sino también para otros
 casos de uso, como una experiencia y apreciación enriquecidas al escuchar
 música, y fines educativos.
\end_layout

\begin_layout Standard
\begin_inset VSpace defskip
\end_inset


\end_layout

\begin_layout Standard

\emph on
(Translated from English by Néstor Nápoles)
\end_layout

\begin_layout Standard
\begin_inset ERT
status collapsed

\begin_layout Plain Layout


\backslash
cleartorecto
\end_layout

\end_inset

 
\begin_inset ERT
status collapsed

\begin_layout Plain Layout


\backslash
traditionalparskip
\end_layout

\end_inset

 
\begin_inset CommandInset toc
LatexCommand tableofcontents

\end_inset


\begin_inset Newpage newpage
\end_inset


\begin_inset FloatList figure

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Newpage newpage
\end_inset


\begin_inset FloatList table

\end_inset


\begin_inset Newpage newpage
\end_inset


\end_layout

\begin_layout Standard
\begin_inset ERT
status collapsed

\begin_layout Plain Layout


\backslash
setlength{
\backslash
parindent}{0in}
\end_layout

\end_inset

 
\begin_inset ERT
status collapsed

\begin_layout Plain Layout


\backslash
nonzeroparskip
\end_layout

\end_inset


\end_layout

\begin_layout Standard
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
mainmatter
\end_layout

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Note Note
status open

\begin_layout Plain Layout
Add chapters with 
\begin_inset Quotes eld
\end_inset

include
\begin_inset Quotes erd
\end_inset


\end_layout

\end_inset


\begin_inset CommandInset include
LatexCommand include
filename "1-introduction.lyx"

\end_inset


\end_layout

\begin_layout Standard
\begin_inset CommandInset include
LatexCommand include
filename "2-background.lyx"

\end_inset


\end_layout

\begin_layout Standard
\begin_inset CommandInset include
LatexCommand include
filename "3-baseline.lyx"

\end_inset


\end_layout

\begin_layout Standard
\begin_inset CommandInset include
LatexCommand include
filename "4-mid-level.lyx"

\end_inset


\end_layout

\begin_layout Standard
\begin_inset CommandInset include
LatexCommand include
filename "5-fine-level.lyx"

\end_inset


\end_layout

\begin_layout Standard
\begin_inset CommandInset include
LatexCommand include
filename "6-Conclusions.lyx"

\end_inset


\end_layout

\begin_layout Standard
\start_of_appendix
\begin_inset Note Note
status open

\begin_layout Plain Layout
Your appendices
\end_layout

\end_inset


\begin_inset CommandInset include
LatexCommand include
filename "Appendix.lyx"

\end_inset


\end_layout

\begin_layout Standard
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
printglossary[type=
\backslash
acronymtype,title=Abbreviations]
\end_layout

\end_inset


\end_layout

\begin_layout Standard
\begin_inset CommandInset include
LatexCommand include
filename "Appendix-publications.lyx"

\end_inset


\end_layout

\begin_layout Standard
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
renewcommand
\backslash
bibname{Bibliography}
\end_layout

\end_inset


\end_layout

\begin_layout Standard
\begin_inset CommandInset bibtex
LatexCommand bibtex
bibfiles "JabRefOnsetDetectionFullReferences"
options "chicago-ff"

\end_inset


\size footnotesize

\begin_inset CommandInset index_print
LatexCommand printindex
type "idx"

\end_inset


\end_layout

\end_body
\end_document

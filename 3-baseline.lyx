#LyX 2.2 created this file. For more info see http://www.lyx.org/
\lyxformat 508
\begin_document
\begin_header
\save_transient_properties true
\origin unavailable
\textclass memoir
\options noend,nofillcomment,figure
\use_default_options false
\maintain_unincluded_children false
\language english
\language_package default
\inputencoding auto
\fontencoding default
\font_roman "default" "default"
\font_sans "default" "default"
\font_typewriter "default" "default"
\font_math "auto" "auto"
\font_default_family default
\use_non_tex_fonts true
\font_sc false
\font_osf false
\font_sf_scale 100 100
\font_tt_scale 100 100
\graphics default
\default_output_format pdf4
\output_sync 0
\bibtex_command default
\index_command default
\paperfontsize 11
\spacing single
\use_hyperref true
\pdf_title "Your topic"
\pdf_author "You"
\pdf_subject "This is about this and that"
\pdf_keywords "comma separated, as many, as you want"
\pdf_bookmarks false
\pdf_bookmarksnumbered false
\pdf_bookmarksopen false
\pdf_bookmarksopenlevel 1
\pdf_breaklinks false
\pdf_pdfborder false
\pdf_colorlinks false
\pdf_backref page
\pdf_pdfusetitle false
\pdf_quoted_options "pdftex,hyperfigures,breaklinks,colorlinks,pdfcreator={LaTeX with hyperref package},pdfproducer={pdflatex},citecolor=LinkColor,linkcolor=LinkColor,urlcolor=ExtLinkColor"
\papersize a4paper
\use_geometry false
\use_package amsmath 2
\use_package amssymb 2
\use_package cancel 0
\use_package esint 1
\use_package mathdots 0
\use_package mathtools 0
\use_package mhchem 0
\use_package stackrel 0
\use_package stmaryrd 0
\use_package undertilde 0
\cite_engine natbib
\cite_engine_type authoryear
\biblio_style plainnat
\use_bibtopic false
\use_indices false
\paperorientation portrait
\suppress_date false
\justification true
\use_refstyle 0
\index Index
\shortcut idx
\color #008000
\end_index
\secnumdepth 3
\tocdepth 3
\paragraph_separation indent
\paragraph_indentation default
\quotes_language english
\papercolumns 1
\papersides 2
\paperpagestyle default
\tracking_changes false
\output_changes false
\html_math_output 0
\html_css_as_file 0
\html_be_strict false
\end_header

\begin_body

\begin_layout Chapter
Baseline Lyrics-to-audio Alignment Model
\end_layout

\begin_layout Section
Introduction
\end_layout

\begin_layout Standard
In this chapter we describe our 
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
gls{LAA}
\end_layout

\end_inset

 baseline system.
 It is a phonetic recognizer, based on phoneme 
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
gls{HMM}
\end_layout

\end_inset

-s.
 To date most of the studies on 
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
gls{LAA}
\end_layout

\end_inset

 are based on the phonetic recognizer approach, as described in Section
 
\begin_inset CommandInset ref
LatexCommand ref
reference "sec:Background-on-Lyrics-to-Audio"

\end_inset

.
 The goal is to describe the key elements of the baseline approach, which
 are not related to the complementary context of lyrics.
 In this way we 
\begin_inset Quotes eld
\end_inset

set the scene
\begin_inset Quotes erd
\end_inset

 for the methods that consider context — the main contribution of this thesis.
 They will be the focus of the following two chapters.
 In this chapter we go through the key steps of a phonetic recognizer and
 describe which existing methods we plugged in.
 Some of these are tailored to the specific characteristics of 
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
gls{OTMM}
\end_layout

\end_inset

 (see Section 
\begin_inset CommandInset ref
LatexCommand ref
reference "sec:Background-on-Ottoman"

\end_inset

).
 In particular, we explain how we utilized a method for linking structural
 sections of the composition to their respective audio segments in a recording.
 Further, we describe the benefit of a predominant melody extraction method,
 whereby we comment on tuning its parameters.
 We present in more detail the construction of the phoneme network from
 the lyrics transcription, for which some rules for Turkish language are
 required.
\end_layout

\begin_layout Standard
A major contribution of this chapter is a strategy to represent phonemes
 in the Turkish language by mapping them to phonemes in English.
 This enables the use of a reliable model for English as a viable replacement
 for Turkish, for which the available training material is scarce.
 We also describe the datasets used to evaluate the 
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
gls{LAA}
\end_layout

\end_inset

 methods, presented throughout this thesis.
 Compiling datasets, representative of the music tradition and the key facets
 of complementary context, is an important effort of this study.
\end_layout

\begin_layout Standard
We start the chapter by describing the evaluation datasets, comprising both
 
\emph on
a cappella
\emph default
 and multi-instrumental recordings from 
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
gls{OTMM}
\end_layout

\end_inset

 (Section 
\begin_inset CommandInset ref
LatexCommand ref
reference "sec:Dataset"

\end_inset

).
 We then introduce our choices for each of the steps of the standard phonetic
 recognizer in Section 
\begin_inset CommandInset ref
LatexCommand ref
reference "sec:Steps-of-phonetic"

\end_inset

.
 We describe the construction of the phoneme network in Section 
\begin_inset CommandInset ref
LatexCommand ref
reference "subsec:Accompaniment-attenuation"

\end_inset

.
 In Section 
\begin_inset CommandInset ref
LatexCommand ref
reference "sec:Training-the-acoustic"

\end_inset

, we present a comparison of three strategies to train the acoustic model
 for Turkish language.
 Finally, in Section 
\begin_inset CommandInset ref
LatexCommand ref
reference "sec:Evaluation"

\end_inset

 we discuss the alignment results by evaluating the baseline model on the
 presented datasets.
\end_layout

\begin_layout Section
Datasets
\begin_inset CommandInset label
LatexCommand label
name "sec:Dataset"

\end_inset


\end_layout

\begin_layout Standard
In this thesis we evaluate the proposed lyrics tracking approaches on datasets
 of selected recordings from 
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
gls{OTMM}
\end_layout

\end_inset

 and jingju repertoire.
 To this end we prepared two datasets: 
\emph on
multi-instrumental lyrics OTMM dataset, 
\emph default
which encompasses original studio recordings with accompaniment of multiple
 instruments, and an 
\emph on
a cappella lyrics OTMM dataset, 
\emph default
which contains solo signing voice
\emph on
.

\emph default
 Additionally, we compiled a 
\emph on
multi-instrumental vocal onsets OTMM dataset
\emph default
 with annotations of vocal note onsets containing performances with well-perceiv
ed percussive accents.
 In all datasets we payed special attention to annotating carefully the
 timestamps of the music events, in which complementary context manifests.
\end_layout

\begin_layout Subsection

\emph on
Multi-instrumental lyrics OTMM dataset
\begin_inset CommandInset label
LatexCommand label
name "subsec:Accompanied-vocal-OTMM"

\end_inset


\end_layout

\begin_layout Standard

\color black
The 
\emph on
\color inherit
multi-instrumental lyrics OTMM dataset, 
\emph default
which
\color black
 we compiled, consists of 13 performances with a soloing singer — 5 with
 male and 8 with female one.
 The performances are from 11 compositions in the şarkı form and have
\color inherit
 total duration of 
\color black
19 minutes.
 They are drawn from the 
\emph on
CompMusic
\emph default

\begin_inset ERT
status open

\begin_layout Plain Layout

{}
\end_layout

\end_inset

 corpus of 
\color inherit

\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
gls{OTMM}
\end_layout

\end_inset


\color black
 repertoire 
\begin_inset CommandInset citation
LatexCommand citep
key "uyar2014corpus_dlfm"

\end_inset

 and
\color inherit
 have varying recording quality, including historic recordings.
 Some these are not necessarily with good studio quality.

\color black
 Music scores are provided in a custom machine-readable format, called 
\emph on
symbTr,
\emph default

\begin_inset ERT
status open

\begin_layout Plain Layout

{}
\end_layout

\end_inset

 complying with the 
\emph on
humdrum
\emph default
 notation philosophy 
\begin_inset CommandInset citation
LatexCommand citep
key "karaosmanouglu2012turkish"

\end_inset

.
 These scores contain annotations of the structural sections of the şarkı
 form.
 
\color inherit
The words in a section are further split adopting the division into musical
 phrases, proposed by 
\begin_inset CommandInset citation
LatexCommand citet
key "karaosmanouglu2014symbolic"

\end_inset

.
 What the authors call a musical phrase represents a musically-meaningful
 melodic motif.
 A phrase spans roughly the same number of metrical cycles depending on
 the tempo (1 or 2 cycles).
 This corresponds to up to 4 words depending on their length.
 A musical phrase often also contains short instrumental motives before
 or after the vocal is present.
 If an original phrase boundary splits a word we have modified it to include
 the complete word, in order to assure appropriate evaluation on word or
 phrase level.
 Table 
\begin_inset CommandInset ref
LatexCommand ref
reference "dataset-1"

\end_inset

 presents statistics about the derived phrases of lyrics.
 The total number of words in the dataset are 732.
\end_layout

\begin_layout Standard

\color black
The performance recordings contain the annotations of the boundaries of
 segments corresponding to the score sections, which have been done in the
 study of 
\begin_inset CommandInset citation
LatexCommand citet
key "senturk2014linking_jnmr"

\end_inset

.
 We annotated further the musical phrase boundaries using the 
\emph on
Praat
\emph default
 annotation tool
\begin_inset Foot
status collapsed

\begin_layout Plain Layout

\color black
\begin_inset CommandInset href
LatexCommand href
target "http://www.fon.hum.uva.nl/praat/"

\end_inset


\end_layout

\end_inset

.

\color inherit
 Whenever needed, we split or merged some lyrics phrases with outlier duration
 so that phrases within a recording have approximately equal duration
\begin_inset Foot
status collapsed

\begin_layout Plain Layout
The dataset is available at 
\begin_inset CommandInset href
LatexCommand href
target "http://compmusic.upf.edu/turkish-sarki"

\end_inset


\end_layout

\end_inset

.
\end_layout

\begin_layout Standard
\begin_inset Float table
wide false
sideways false
status open

\begin_layout Plain Layout
\align center
\begin_inset Tabular
<lyxtabular version="3" rows="2" columns="3">
<features booktabs="true" tabularvalignment="middle">
<column alignment="center" valignment="top">
<column alignment="center" valignment="top">
<column alignment="center" valignment="top">
<row>
<cell alignment="center" valignment="top" topline="true" bottomline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
total #sections 
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
#phrases per section 
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
#words per phrase
\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="center" valignment="top" topline="true" bottomline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
75 
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
2 to 5 
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
1 to 4
\end_layout

\end_inset
</cell>
</row>
</lyxtabular>

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption Standard

\begin_layout Plain Layout
Phrase and section statistics for the 
\emph on
multi-instrumental lyrics OTMM dataset
\end_layout

\end_inset


\begin_inset CommandInset label
LatexCommand label
name "dataset-1"

\end_inset

 
\end_layout

\end_inset


\end_layout

\begin_layout Subsection

\emph on
A cappella lyrics OTMM dataset
\begin_inset CommandInset label
LatexCommand label
name "subsec:A-cappella-lyrics-1"

\end_inset


\end_layout

\begin_layout Standard
Due to the lack of appropriate 
\emph on
a cappella
\emph default
 material in the şarkı form, we recorded especially for this study an 
\emph on
a cappella
\emph default
 version of the 
\emph on
accompanied vocal OTMM dataset
\emph default
.
\end_layout

\begin_layout Standard

\color black
The vocal parts of the 
\emph on
\color inherit
multi-instrumental lyrics OTMM dataset
\emph default
\color black
 have been sung by professional singers,
\color inherit
 especially recorded for this study.
 A performance has been recorded while listening to the original recording,
 whereby instrumental sections are left as silence.
 This assures that the order, in which sections are performed, is kept the
 same.
 Therefore, the generated timestamps are valid for the accompanied version,
 too.
 Although each recorded singer sings sporadically off-time at some syllables,
 the recordings are to a very high degree in-sync with the originals.
 We carefully validated that by listening simultaneously to both the original
 and the 
\emph on
a cappella
\emph default
 version
\begin_inset Foot
status collapsed

\begin_layout Plain Layout
The audio and the annotations are available under a CC license at 
\begin_inset CommandInset href
LatexCommand href
target "http://compmusic.upf.edu/turkish-makam-acapella-sections-dataset"

\end_inset


\end_layout

\end_inset

.
\end_layout

\begin_layout Standard
Additionally, the singing voice for 6 recordings (with a total duration
 of around 10 minutes) from the dataset has been manually transcribed with
 notes, inferred by the music score.
 A special care is taken to place the onset annotation on the time instant,
 where a voiced sound starts.
 In this way, an onset is considered to be always at the beginning of a
 portamento, when it is present (it is common for some singers)
\begin_inset Foot
status open

\begin_layout Plain Layout
Onset annotations are available at 
\begin_inset CommandInset href
LatexCommand href
target "http://compmusic.upf.edu/node/233"

\end_inset


\end_layout

\end_inset

.
 Similarly, if a syllable starts with an unvoiced consonant, the onset is
 placed at the beginning of the succeeding vowel (see Figure 5.3).
\begin_inset Note Comment
status open

\begin_layout Plain Layout
IMPL: a cappella dataset is in /Users/joro/Downloads/ISTANBULSymbTr2/ and
 polyphonic dataset is in ~/Downloads/lyrics-2-audio-test-data/ 
\end_layout

\end_inset


\end_layout

\begin_layout Subsection

\emph on
Multi-instrumental vocal onsets OTMM dataset
\begin_inset CommandInset label
LatexCommand label
name "subsec:Multi-instrumental-vocal-onsets"

\end_inset


\end_layout

\begin_layout Standard
Unlike the previous two datasets, being designed for 
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
gls{LAA}
\end_layout

\end_inset

, we compiled 
\emph on
the multi-instrumental vocal onsets OTMM dataset
\emph default
 to be used for note onset detection of singing voice.
 We utilize it for automatic note onset detection, informed by underlying
 metrical accents.
 To that end, all recordings have clearly audible percussive strokes, at
 some of the beats in a metrical cycle.
 The dataset includes two meter types, referred to as usuls in Turkish makam:
 the 9/8-usul aksak and the 8/8-usul d
\begin_inset ERT
status open

\begin_layout Plain Layout

{
\backslash
"u}
\end_layout

\end_inset

yek.
 It is a subset of the dataset presented in 
\begin_inset CommandInset citation
LatexCommand cite
key "holzapfel2014tracking"

\end_inset

, including only the recordings with singing voice present.
 The beats and downbeats were annotated by 
\begin_inset CommandInset citation
LatexCommand cite
key "holzapfel2014tracking"

\end_inset

.
 The vocal note onsets are annotated by a single annotator, whereby only
 pitched onsets are considered (2100 onsets).
 To this end, we had the same strategy for annotation onsets as in the 
\emph on
a cappella lyrics OTMM dataset
\emph default

\begin_inset Foot
status collapsed

\begin_layout Plain Layout
The dataset is available at 
\begin_inset CommandInset href
LatexCommand href
name "http://compmusic.upf.edu/node/345"
target "http://compmusic.upf.edu/node/345"

\end_inset


\end_layout

\end_inset

.
 Unlike it, however, we used as guidance the annotated beats — being aware
 of the location of a beat helped to put more precisely the location of
 an onset.
 Annotations were done as different layers in 
\emph on
Sonic Visualiser
\emph default

\begin_inset Foot
status open

\begin_layout Plain Layout
\begin_inset CommandInset href
LatexCommand href
target "http://www.sonicvisualiser.org/"

\end_inset


\end_layout

\end_inset

.
\end_layout

\begin_layout Subsection

\emph on
A cappella lyrics jingju dataset
\begin_inset CommandInset label
LatexCommand label
name "subsec:A-cappella-lyrics"

\end_inset


\end_layout

\begin_layout Standard
The dataset has been especially compiled for this study and consists of
 excerpts from 15 arias, chosen from the 
\emph on
CompMusic
\emph default
 corpus of jingju arias, compiled by 
\begin_inset CommandInset citation
LatexCommand citet
key "repetto2014creating"

\end_inset

.
 It has total duration of 67 minutes and comprises two female singers.
 For a given aria were present two versions: a recording with voice plus
 accompaniment and an accompaniment-only one.
 From these, we generated 
\emph on
a cappella
\emph default
 singing by subtracting manually the instrumental accompaniment from the
 complete version
\begin_inset Foot
status collapsed

\begin_layout Plain Layout
The resulting monophonic singing is perceived as clean as if it were a cappella,
 having slightly audible artifacts from percussion on the non-vocal regions
\end_layout

\end_inset

.
 Table 
\begin_inset CommandInset ref
LatexCommand ref
reference "dataset"

\end_inset

 presents the average values per sentence and syllable.
\end_layout

\begin_layout Standard
\begin_inset Float table
wide false
sideways false
status collapsed

\begin_layout Plain Layout
\align center
\begin_inset Tabular
<lyxtabular version="3" rows="4" columns="2">
<features booktabs="true" tabularvalignment="middle">
<column alignment="center" valignment="top">
<column alignment="center" valignment="top" width="0pt">
<row>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
#sentences per aria
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
9.2
\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
#syllables per sentence
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
10.7
\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="center" valignment="top" topline="true" bottomline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
avrg sentence duration (sec)
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
18.3
\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="center" valignment="top" topline="true" bottomline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
avrg syllable duration (sec)
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" bottomline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
2.4
\end_layout

\end_inset
</cell>
</row>
</lyxtabular>

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption Standard

\begin_layout Plain Layout
Sentence and syllable statistics for the jingju dataset
\end_layout

\end_inset


\begin_inset CommandInset label
LatexCommand label
name "dataset"

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Standard
Each aria is annotated on different event granularities: from the 
\emph on
banshi
\emph default
 type, through boundaries of lyrics sentences, down to boundaries of syllables
 and boundaries of phonemes.
 Annotations are carefully done by native Chinese speakers and a jingju
 opera musicologist
\begin_inset Foot
status open

\begin_layout Plain Layout
These are the 
\emph on
CompMusic 
\emph default
team members Rong Gong, Yile Yang and Rafael Caro Repetto
\end_layout

\end_inset

.
 The phoneme set has 29 phonemes and is derived from Chinese pinyin, and
 represented using the x-sampa standard
\begin_inset Foot
status collapsed

\begin_layout Plain Layout
Annotations are made available at 
\begin_inset CommandInset href
LatexCommand href
target "http://compmusic.upf.edu/node/286"

\end_inset


\end_layout

\end_inset

.
 To assure enough training data for each model, certain underrepresented
 phonemes are grouped into phonetic classes, based on their perceptual similarit
y.
\end_layout

\begin_layout Section
Phonetic recognizer
\begin_inset CommandInset label
LatexCommand label
name "sec:Steps-of-phonetic"

\end_inset


\end_layout

\begin_layout Standard
An overview of the steps of the proposed approach can be seen in Figure
 
\begin_inset CommandInset ref
LatexCommand ref
reference "overview_baseline"

\end_inset

.
 These steps follows some of the the typical steps of existing phonetic
 recognizer approaches (presented in Fig.
 
\begin_inset CommandInset ref
LatexCommand ref
reference "steps_phonetic_recognizer"

\end_inset

 of the Background Chapter).
 In what follows we discuss in detail the design choices and the preferred
 solutions for each step.
\end_layout

\begin_layout Standard
\begin_inset Float figure
wide false
sideways false
status collapsed

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename Phd_Figs/baseline/LAA_baseline_overview.png
	lyxscale 20
	width 100text%

\end_inset

 
\end_layout

\begin_layout Plain Layout
\begin_inset Caption Standard

\begin_layout Plain Layout
Overview of the steps of the baseline lyrics-to-audio alignment system
\end_layout

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset CommandInset label
LatexCommand label
name "overview_baseline"

\end_inset

 
\end_layout

\end_inset


\end_layout

\begin_layout Subsection
Structural segmentation
\end_layout

\begin_layout Standard
Being a challenging problem itself, a full-fledged 
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
gls{VAD}
\end_layout

\end_inset

 is outside the scope of this study.
 We instead divided manually each audio recording into sections (e.g.
 zemin, nakarat, meyan) as indicated in the music score, whereby instrumental-on
ly sections were discarded.
 In the şarkı form each vocal segment corresponds to a structural section
 (zemin, nakarat, or meyan).
 We assign manually to each segmented vocal section its corresponding lyrical
 line, in order to assure correct lyrics.
\end_layout

\begin_layout Standard
All alignment throughout this thesis is performed on an audio recording
 and text for each vocal section separately.
 
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
gls{LAA}
\end_layout

\end_inset

 on complete audio recordings was not desirable due to the unpredictability
 of the sections order in a şarkı form.
 The sections are often performed in an order differing from that indicated
 in the score.
 On top of that, improvisation sections not present in the score are commonly
 inserted 
\begin_inset CommandInset citation
LatexCommand citep
key "judetz1996meanings"

\end_inset

.
\end_layout

\begin_layout Standard
To verify the feasibility of automating the structural segmentation, we
 utilized a method for linking score sections to their beginning and ending
 timestamps in a recording with Makam singing 
\begin_inset CommandInset citation
LatexCommand citep
key "senturk2014linking_jnmr"

\end_inset

.
 Due to the high accuracy of this method, almost all sections are mapped
 correctly with minor section boundary displacements.
 We showed that integrating section linking as a preprocessing step yields
 estimated section boundaries that are not detrimental to matching the correct
 lyrics sections 
\begin_inset CommandInset citation
LatexCommand citep
key "dzhambazov2014lyrics_fma"

\end_inset

.
\end_layout

\begin_layout Subsection
Accompaniment attenuation
\begin_inset CommandInset label
LatexCommand label
name "subsec:Accompaniment-attenuation"

\end_inset


\end_layout

\begin_layout Standard
It is difficult to successfully track the phonemes in multi-instrumental
 music signals by using the models, trained solely on 
\emph on
a cappella
\emph default
 singing.
 The harmonic partials in unaccompanied singing can be extracted relatively
 reliably, mainly because they form clear intensity peaks in the spectrogram
\series bold
 
\begin_inset CommandInset citation
LatexCommand citep
key "serra1990spectral"

\end_inset


\series default
.
 A simple intensity-peak-picking strategy is however prone to failure in
 accompanied singing, because of the interference with instrumental harmonic
 partials.
 To handle this case many harmonic partial detection methods were proposed
 (see Section 
\begin_inset CommandInset ref
LatexCommand ref
reference "subsec:Background-Accompaniment-attenuation"

\end_inset

).
\end_layout

\begin_layout Standard
Such a method for the detection of vocal harmonic partials requires a melody
 contour as an input, being generated by a melodic source.
 We first extract the vocal contour of the singing voice.
 Then, based on it, its harmonic partials are derived from the spectrum
 
\begin_inset Formula $Y$
\end_inset

 at a given time frame.
 Then the vocal harmonic partials are resynthesized into an interpolated
 vocal spectrum 
\begin_inset Formula $Yh$
\end_inset

.
 Finally, we extract acoustic features from 
\begin_inset Formula $Yh$
\end_inset

 instead of the original polyphonic spectrum 
\begin_inset Formula $Y$
\end_inset

.
\end_layout

\begin_layout Subsubsection
Singing voice melody extraction
\begin_inset CommandInset label
LatexCommand label
name "subsec:Singing-voice-melody"

\end_inset


\end_layout

\begin_layout Standard
To extract the contour of the predominant singing voice in music with instrument
al accompaniment, we utilized the algorithm described in 
\begin_inset CommandInset citation
LatexCommand citet
key "atli2014audio"

\end_inset

.
 It is a method for the extraction of the melody of a predominant instrument.
 It relies on the basic methodology of 
\begin_inset CommandInset citation
LatexCommand citet
key "salamon2012melody"

\end_inset

, but modifies the way in which the final melody contour is selected from
 a set of candidate contours, in order to reflect the specificities of 
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
gls{OTMM}
\end_layout

\end_inset

: 
\end_layout

\begin_layout Enumerate
It chooses a finer bin resolution of only 7.5 cents that approximately correspond
s to the smallest noticeable change in Makam melodic scales.
 
\end_layout

\begin_layout Enumerate
Unlike the original methodology, it does not discard time intervals where
 the peaks of the pitch contours have relatively low magnitude.
 This accommodates time intervals at the end of the melodies, where Makam
 singers might sing softer.
 
\end_layout

\begin_layout Standard
In addition to generating fundamental frequency values (
\begin_inset Formula $f_{0}$
\end_inset

) values, the algorithm performs in the same time a predominant source detection
: it returns zero values for
\begin_inset Formula $f_{0}$
\end_inset

 in regions with no predominant melody.
 The melody contour obtained this way has its origin not only from singing
 voice but also from accompanying instruments.
 This happens in short instrumental interludes, where an accompanying instrument
 carries the main melody.
\end_layout

\begin_layout Subsubsection
Harmonic model
\end_layout

\begin_layout Standard
We utilized the harmonic model of 
\begin_inset CommandInset citation
LatexCommand citet
key "serra1990spectral"

\end_inset

 to filter the spectral peaks corresponding to the harmonic partials of
 the singing voice.
 The spectral peaks are computed at the expected location of harmonic partials
 at multiples of the normalized fundamental frequency 
\begin_inset Formula $\hat{f_{0}}$
\end_inset

.
 Equation 
\begin_inset CommandInset ref
LatexCommand ref
reference "eq:harmonic-model"

\end_inset

 represents a spectral bin 
\emph on

\begin_inset Formula $k$
\end_inset


\emph default
 as the sum of 
\emph on

\begin_inset Formula $R$
\end_inset


\emph default
 harmonic partials from the spectrum of the analysis window 
\begin_inset Formula $W$
\end_inset

, weighted by their
\emph on
 
\emph default
corresponding amplitudes
\emph on
 
\begin_inset Formula $A_{r}$
\end_inset


\emph default
 
\begin_inset CommandInset citation
LatexCommand citet
key "Serra:lecture"

\end_inset

.
 Parabolic interpolation refines the exact frequency locations.
 We estimated 
\begin_inset Formula $Yh$
\end_inset

 with a relatively large number of harmonics (
\begin_inset Formula $R=30$
\end_inset

), in order to preserve as much as possible the phonetic timbre.
\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{equation}
Yh[k]=\sum_{r=1}^{R}A_{r}W[k-r\hat{f}_{0}]\label{eq:harmonic-model}
\end{equation}

\end_inset


\end_layout

\begin_layout Standard
\align center
\begin_inset Float figure
placement h
wide false
sideways false
status collapsed

\begin_layout Plain Layout
\align center
\begin_inset Float figure
wide false
sideways false
status collapsed

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename Phd_Figs/baseline/example_fundFreq.png
	width 40page%

\end_inset

 
\end_layout

\begin_layout Plain Layout
\begin_inset Caption Standard

\begin_layout Plain Layout
Extracted fundamental frequency 
\begin_inset Formula $f_{0}$
\end_inset

 of the predominant melody
\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Plain Layout
\align center
\begin_inset VSpace medskip
\end_inset

 
\end_layout

\begin_layout Plain Layout
\align center
\begin_inset Float figure
wide false
sideways false
status collapsed

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename Phd_Figs/baseline/example_fundFreq_harmonics.png
	width 40page%

\end_inset

 
\end_layout

\begin_layout Plain Layout
\begin_inset Caption Standard

\begin_layout Plain Layout
Detected harmonic partials (R=4) with the harmonic model, based on the fundament
al frequency 
\begin_inset Formula $f_{0}$
\end_inset

 of the predominant melody
\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Plain Layout
\align center
\begin_inset Caption Standard

\begin_layout Plain Layout
An example of extracting harmonic partials of predominant voice with the
 harmonic model
\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Standard
It should be noted that it is not an end goal of this study to have the
 best possible segregation of the singing voice from the polyphonic mix.
 Segregation methods strive to obtain a representation of the vocal content
 with the least amount of introduced artifacts.
 In contrast to that, in our case some artifacts may be acceptable as long
 as they do not distort significantly the intelligibility of vowels.
 As a benchmark, we carried out a study, in which we evaluated the quality
 of voice segregation using the harmonic model 
\begin_inset CommandInset citation
LatexCommand citep
key "dzhambazov_svs_mirex"

\end_inset

.
 Results in terms of the common source separation metrics showed that for
 pop music the harmonic model is inferior to recent separation methods based
 on convolutional neural networks, like for example the method of 
\begin_inset CommandInset citation
LatexCommand citep
key "chandna2017monoaural"

\end_inset


\begin_inset Foot
status open

\begin_layout Plain Layout
results on the MIREX 2016 task on singing voice separation are available
 at 
\begin_inset CommandInset href
LatexCommand href
target "http://www.music-ir.org/mirex/wiki/2016:Singing_Voice_Separation_Results"

\end_inset

 
\end_layout

\end_inset

.
 However, a shortcoming of convolutional neural networks is the necessity
 of a big amount of clean singing voice training data, which was not available
 for 
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
gls{OTMM}
\end_layout

\end_inset

.
 
\end_layout

\begin_layout Subsubsection
Resynthesis
\end_layout

\begin_layout Standard
The interpolated vocal harmonic partials are resynthesized by means of a
 constant overlap add resynthesis with the 
\emph on
sms-tools
\emph default
 package
\begin_inset Foot
status collapsed

\begin_layout Plain Layout
\begin_inset CommandInset href
LatexCommand href
target "http://mtg.upf.edu/technologies/sms"

\end_inset


\end_layout

\end_inset

.
 Despite being distorted by energy leaks from instruments, the interpolated
 partials seem to preserve well the overall spectral shape of the singing
 voice, including the formant frequencies, which encode the phoneme identities.
 The resynthesis allowed us to listen and verify that vocals are still to
 a large extent intelligible.
\end_layout

\begin_layout Standard
Note that melody resynthesis usually results in singing voice with perceivably
 worse intelligibility of the phonemes than the original signal.
 Some unvoiced consonants are dropped, as well as some artifacts are introduced.
 However, for computers, which are not as versed as human listeners in distingui
shing among sources, the accompaniment reduction is an imperative step.
\end_layout

\begin_layout Standard
An example for the audio segment with the lyrics phrase 
\emph on
bakmıyor çeşmi siyah
\emph default
 can be seen in Figure 
\begin_inset CommandInset ref
LatexCommand ref
reference "figure_resynthesis"

\end_inset

.
 
\end_layout

\begin_layout Standard
\align center
\begin_inset Float figure
placement h
wide false
sideways false
status collapsed

\begin_layout Plain Layout
\align center
\begin_inset Float figure
wide false
sideways false
status open

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename Phd_Figs/baseline/spectrogramOriginalWithLyrics.png
	width 40page%

\end_inset

 
\end_layout

\begin_layout Plain Layout
\begin_inset Caption Standard

\begin_layout Plain Layout
Original spectrogram.
\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Plain Layout
\align center
\begin_inset VSpace medskip
\end_inset

 
\end_layout

\begin_layout Plain Layout
\align center
\begin_inset Float figure
wide false
sideways false
status collapsed

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename Phd_Figs/baseline/spectrogramSynthesisWithLyrics.png
	width 40page%

\end_inset

 
\end_layout

\begin_layout Plain Layout
\begin_inset Caption Standard

\begin_layout Plain Layout
Spectrogram of resynthesized harmonic partials content.
 Note that some unvoiced consonants are replaced with silences 
\end_layout

\end_inset


\begin_inset CommandInset label
LatexCommand label
name "figure_resynthesis"

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Plain Layout
\align center
\begin_inset Caption Standard

\begin_layout Plain Layout
An example of the resynthesized harmonic partials of singing voice for the
 lyrics phrase 
\emph on
bakmıyor çeşmi siyah.
 
\emph default
Content up to 10 kHz is shown.
\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Subsection
Acoustic Features
\begin_inset CommandInset label
LatexCommand label
name "subsec:Features"

\end_inset


\end_layout

\begin_layout Standard

\end_layout

\begin_layout Standard
The 
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
gls{MFCC}
\end_layout

\end_inset

 have several parameters that could be tuned according to the application
 use case.
 A standard for their extracting for the characterization of singing voice
 are the default parameters of the 
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
gls{HMM}
\end_layout

\end_inset

 toolkit (
\emph on
htk
\emph default
), which is tailored to speech recognition 
\begin_inset CommandInset citation
LatexCommand citep
key "young1993htk"

\end_inset

.
 The parameters are presented in Table 
\begin_inset CommandInset ref
LatexCommand ref
reference "table-params_MFCC"

\end_inset

 and are explained in detail in the 
\emph on
htk book
\emph default

\begin_inset Foot
status open

\begin_layout Plain Layout
\begin_inset CommandInset href
LatexCommand href
target "https://www.researchgate.net/publication/236023819_The_HTK_book_for_HTK_version_34"

\end_inset


\end_layout

\end_inset

.
 We adopted these to assure consistency to previous work, as in fact all
 the background lyrics-to-audio alignment approaches reviewed in the previous
 chapter rely on the htk variant of MFCC features.
 We believe that an important contribution of this work, from a practical
 point of view, is that we ported the variant of MFCC with the 
\emph on
htk
\emph default
 parameters to the open-source feature extraction library 
\emph on
essentia
\emph default

\begin_inset Foot
status open

\begin_layout Plain Layout
\begin_inset CommandInset href
LatexCommand href
target "http://essentia.upf.edu/documentation/"

\end_inset


\end_layout

\end_inset

.
 Reducing the dependency on 
\emph on
htk
\emph default
 encourages the easier reproducibility and extensibility of this research
\begin_inset Foot
status open

\begin_layout Plain Layout
A walkthrough on how to reproduce the htk-parameters in 
\emph on
essentia
\emph default
 is available at 
\begin_inset CommandInset href
LatexCommand href
target "https://github.com/georgid/mfcc-htk-an-librosa/blob/master/mfcc_parameters_comparison_essentia.ipynb"

\end_inset


\end_layout

\end_inset

.
 
\end_layout

\begin_layout Standard
\begin_inset Float table
wide false
sideways false
status open

\begin_layout Plain Layout

\emph on
TARGETKIND = MFCC_0_D_A_Z
\end_layout

\begin_layout Plain Layout

\emph on
TARGETRATE = 100000.0
\end_layout

\begin_layout Plain Layout

\emph on
WINDOWSIZE = 250000.0
\end_layout

\begin_layout Plain Layout

\emph on
USEHAMMING = T
\end_layout

\begin_layout Plain Layout

\emph on
PREEMCOEF = 0.97
\end_layout

\begin_layout Plain Layout

\emph on
NUMCHANS = 26
\end_layout

\begin_layout Plain Layout

\emph on
CEPLIFTER = 22
\end_layout

\begin_layout Plain Layout

\emph on
NUMCEPS = 12
\end_layout

\begin_layout Plain Layout

\emph on
HIFREQ = 8000
\end_layout

\begin_layout Plain Layout
\begin_inset Caption Standard

\begin_layout Plain Layout
Parameters of the 
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
gls{MFCC}
\end_layout

\end_inset

 extraction (in the 
\emph on
htk
\emph default
 format).
 The target kind of feature has added 0th coefficient for energy (_0), plus
 its frame-to-frame difference (_D) and difference of the difference (_A)
 with zero-mean (_Z).
 The unit of 
\emph on
htk
\emph default
 is 100 nanoseconds, so the frame size is 25 ms, while hopsize is 10 ms.
 26 mel bands and 22 liftering bands are used.
\end_layout

\end_inset


\begin_inset CommandInset label
LatexCommand label
name "table-params_MFCC"

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Subsection
Phoneme network
\end_layout

\begin_layout Standard
The phonetic recognizer is an 
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
gls{HMM}
\end_layout

\end_inset

, whose states represent the sequence of phonemes from the phoneme transcription
 of the lyrics.
 As we described in Section 
\begin_inset CommandInset ref
LatexCommand ref
reference "subsec:Phoneme-network"

\end_inset

 the goal of the grapheme-to-phoneme conversion is to create the phoneme
 transcription out of the word sequence, comprising the input lyrics for
 a particular vocal section.
\end_layout

\begin_layout Standard
A phonetic recognizer 
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
gls{HMM}
\end_layout

\end_inset

 can be represented as a 
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
gls{DBN}
\end_layout

\end_inset

 with a single hidden state for the current phoneme (Figure 
\begin_inset CommandInset ref
LatexCommand ref
reference "DBN_model"

\end_inset

).
 In all DBN diagrams in this thesis we use circles and squares to denote
 continuous and discrete variables, respectively.
 Also gray nodes and white nodes represent observed and hidden variables,
 respectively.
 Although in initial experiments we trained a 3-state-HMM per phoneme, in
 most of the work presented in this dissertation a single-state-HMM was
 preferred.
 Preliminary experiments revealed that the difference in alignment accuracy
 with 3-states is negligible than that with one state.
 In this section we present the derivation of the phoneme network for Turkish.
 While in general the derivation of the phoneme network used for jingju
 is following the same principles, some Mandarin-particular details are
 discussed in Section 
\begin_inset CommandInset ref
LatexCommand ref
reference "par:Training-phoneme-models"

\end_inset

.
 
\end_layout

\begin_layout Standard
\begin_inset Float figure
wide false
sideways false
status collapsed

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename Phd_Figs/baseline/phoneme_DBN.jpg
	scale 30

\end_inset

 
\end_layout

\begin_layout Plain Layout
\begin_inset Caption Standard

\begin_layout Plain Layout
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
gls{DBN}
\end_layout

\end_inset

 for the baseline phonetic recognizer: one hidden variable represents the
 phoneme state.
 Circles and squares denote continuous and discrete variables, respectively.
 Gray nodes and white nodes represent observed and hidden variables, respectivel
y.
\end_layout

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset CommandInset label
LatexCommand label
name "DBN_model"

\end_inset

 
\end_layout

\end_inset


\end_layout

\begin_layout Subsubsection
Graphene-to-phoneme conversion
\end_layout

\begin_layout Standard
The words are expanded to phonemes based on a phonetic alphabet.
 Linguists have developed the international phonetic alphabet (IPA) — a
 language-independent notation system of phoneme sounds
\begin_inset Foot
status collapsed

\begin_layout Plain Layout
\begin_inset CommandInset href
LatexCommand href
name "https://en.wikipedia.org/wiki/International_{}Phonetic_{}Alphabet"
target "https://en.wikipedia.org/wiki/International_Phonetic_Alphabet"

\end_inset


\end_layout

\end_inset

, because many of them are not language specific.
 For each language exists one or several options for an alphabet of machine-read
able representation of IPA.
 For Turkish we have adopted the alphabet METUbet, proposed for one of the
 speech recognition state-of-the art systems for Turkish 
\begin_inset CommandInset citation
LatexCommand citep
after "Table 1"
key "Salor2007580"

\end_inset

.
 METUbet is very easy to interpret, because of its intuitiveness.
 All latin written characters are mapped to their corresponding latin phoneme,
 while the characters ç, ş, ı, ö and ü unique to the Turkish language are
 mapped to capital letters — respectively C, S, E, OE and UE.
 The unpronounced ğ is omitted from the transcript, whereas g is represented
 as GG.
\end_layout

\begin_layout Standard
After the grapheme-to-phoneme conversion optional filler silence tokens
 are inserted in between words.
 A silence model represents short non-voiced time intervals, when the singing
 voice is not active to accommodate silent pauses or breaths between words.
 Using METUbet the lyrics phrase
\emph on
 bakmıyor çeşmi siyah
\emph default
 is expanded to a phoneme sequence seen in Figure 
\begin_inset CommandInset ref
LatexCommand ref
reference "phoneme sequence"

\end_inset

.
 Square brackets denote zero or one occurrence of a token, and vertical
 bars denote alternatives.
 Its corresponding phoneme network is depicted in Figure 
\begin_inset CommandInset ref
LatexCommand ref
reference "phoneme_network"

\end_inset

.
 
\end_layout

\begin_layout Standard
\align center
\begin_inset Float figure
placement h
wide false
sideways false
status open

\begin_layout Plain Layout
\align center
\begin_inset Float figure
wide false
sideways false
status open

\begin_layout Plain Layout

\size large
\begin_inset ERT
status collapsed

\begin_layout Plain Layout

{}
\end_layout

\end_inset

[sp] b a k m I y o r [sp] C e S m i [sp] s i y a h [sp]
\end_layout

\begin_layout Plain Layout
\begin_inset CommandInset label
LatexCommand label
name "phoneme sequence"

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption Standard

\begin_layout Plain Layout
Phoneme sequence for the lyrics phrase
\emph on
 bakmıyor çeşmi siyah
\emph default
.
 
\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Plain Layout
\align center
\begin_inset Float figure
wide false
sideways false
status open

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename Phd_Figs/baseline/phoneme_network_bakmiyor.jpg
	width 50page%

\end_inset

 
\end_layout

\begin_layout Plain Layout
\begin_inset CommandInset label
LatexCommand label
name "phoneme_network"

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption Standard

\begin_layout Plain Layout
Phoneme network for the lyrics phrase
\emph on
 bakmıyor çeşmi siyah
\emph default
.
 Arrows indicated possible transitions with non-zero probabilities.
\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption Standard

\begin_layout Plain Layout
An example of the phoneme sequence and phoneme network for the phrase 
\emph on
bakmıyor çeşmi siyah
\emph default
 for 
\emph on
a cappella
\emph default
 voice.
 The phoneme set used is the Turkish METUbet.
 
\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Subsubsection*
Handling accompaniment artifacts
\begin_inset CommandInset label
LatexCommand label
name "subsec:Handling-accompaniment-artifacts"

\end_inset


\end_layout

\begin_layout Standard
The phoneme network for accompanied singing ideally should be identical
 to the 
\emph on
a cappella
\emph default
 one presented above.
 In practice however, some of the phonemes in the accompaniment attenuation
 process are not accurately resynthesized.
 To address such cases, we build the network in a flexible way.
\end_layout

\begin_layout Standard
Except for silences, another filler model for non-vocal parts is introduced:
 a model for the instrumental background.
 We assume that the stochastic characteristics of the background music could
 be approximated by those of the instrumental-only regions in a music recording.
 We therefore trained a 
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
gls{GMM}
\end_layout

\end_inset

 for accompaniment instruments (ACC) from the time intervals, which are
 not annotated as words in the test dataset.
 It has a substantial amount of mixtures (40) to be able to capture the
 diverse timbral characteristics of background instruments.
 It is integrated as a single-state-HMM in the phoneme network.
 Setting the filler models as optional lets the phonetic recognizer activate
 the ACC model, depending on whether sound from background instruments was
 re-synthesized by the sinusoidal model, due to short regions, detected
 falsely as being vocal (see accompaniment attenuation step).
 In addition, this also accommodates potential instrumental leaks due to
 automatically detected boundary timestamps of vocal sections, displaced
 from the actual boundaries of sung lyrics.
\end_layout

\begin_layout Standard
A side effect of the resynthesis is that non-voiced consonants are not synthesiz
ed, which leaves short time intervals of silence.
 Looking carefully at Figure 
\begin_inset CommandInset ref
LatexCommand ref
reference "figure_resynthesis"

\end_inset

 one can notice that the time intervals for most METUbet unvoiced consonants:
 
\emph on
k
\emph default
,
\emph on
 S
\emph default
, 
\emph on
s
\emph default
, and 
\emph on
h
\emph default
 are converted into silences.
 
\begin_inset CommandInset citation
LatexCommand citet
key "fujihara2011lyricsynchronizer"

\end_inset

 suggested to tackle this problem by incorporating a separate method for
 detection of unvoiced consonants in the musical audio.
 The strategy we used instead is replacing unvoiced consonants by silence
 in the phoneme sequence.
 For example, for the phrase 
\emph on
bakmıyor çeşmi siyah
\emph default
 it will look accordingly in Figure 
\begin_inset CommandInset ref
LatexCommand ref
reference "phoneme sequence-1"

\end_inset

.
 
\end_layout

\begin_layout Standard
\align center
\begin_inset Float figure
placement h
wide false
sideways false
status collapsed

\begin_layout Plain Layout
\align center
\begin_inset Float figure
wide false
sideways false
status open

\begin_layout Plain Layout

\size large
\begin_inset ERT
status collapsed

\begin_layout Plain Layout

{}
\end_layout

\end_inset

[sp
\begin_inset ERT
status collapsed

\begin_layout Plain Layout


\backslash
textbar
\end_layout

\end_inset


\begin_inset ERT
status collapsed

\begin_layout Plain Layout

{}
\end_layout

\end_inset

ACC] b a sp m I y o r [sp
\begin_inset ERT
status collapsed

\begin_layout Plain Layout


\backslash
textbar
\end_layout

\end_inset


\begin_inset ERT
status collapsed

\begin_layout Plain Layout

{}
\end_layout

\end_inset

ACC] sp e sp m i [sp
\begin_inset ERT
status collapsed

\begin_layout Plain Layout


\backslash
textbar
\end_layout

\end_inset


\begin_inset ERT
status collapsed

\begin_layout Plain Layout

{}
\end_layout

\end_inset

ACC] sp i y a sp [sp
\begin_inset ERT
status collapsed

\begin_layout Plain Layout


\backslash
textbar
\end_layout

\end_inset


\begin_inset ERT
status collapsed

\begin_layout Plain Layout

{}
\end_layout

\end_inset

ACC]
\end_layout

\begin_layout Plain Layout
\begin_inset CommandInset label
LatexCommand label
name "phoneme sequence-1"

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption Standard

\begin_layout Plain Layout
Phoneme sequence for the lyrics phrase
\emph on
 bakmıyor çeşmi siyah
\emph default
.
\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Plain Layout
\align center
\begin_inset Float figure
wide false
sideways false
status open

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename Phd_Figs/baseline/phoneme_network_bakmiyor_accompaniment.jpg
	width 100text%

\end_inset

 
\end_layout

\begin_layout Plain Layout
\begin_inset CommandInset label
LatexCommand label
name "phoneme_network-1"

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption Standard

\begin_layout Plain Layout
Phoneme network for the lyrics phrase
\emph on
 bakmıyor çeşmi siyah
\emph default
.
 
\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption Standard

\begin_layout Plain Layout
An example of the phoneme sequence and phoneme network for the phrase 
\emph on
bakmıyor çeşmi siyah
\emph default
 when accompanying instruments are present.
 The phoneme set used is the Turkish METUbet 
\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Standard
Figure 
\begin_inset CommandInset ref
LatexCommand ref
reference "phoneme_network-1"

\end_inset

 presents its corresponding phoneme network.
 We evaluated the contribution of this simple resynthesis handling strategy
 by comparing to the performance of alignment between the resynthesizes
 audio and the phoneme network of Figure 
\begin_inset CommandInset ref
LatexCommand ref
reference "phoneme_network"

\end_inset

 that is meant for 
\emph on
a cappella
\emph default
 singing.
 The results (see Table 
\begin_inset CommandInset ref
LatexCommand ref
reference "results baseline"

\end_inset

) outlined a slight improvement with the accompaniment-aware network.
 We inspected carefully the flawed alignment cases with the 
\emph on
a cappella
\emph default
 phoneme network.
 This revealed that sometimes when there is a fricative in the vicinity
 of an inter-word 
\emph on
sp
\emph default
 (for example the 
\emph on
ş
\emph default
 from 
\emph on
çeşmi
\emph default
 following the 
\emph on
sp
\emph default
 between 
\emph on
bakmıyor
\emph default
 and 
\emph on
çeşmi
\emph default
) the Viterbi would confuse the model of 
\emph on
sp
\emph default
 with the 
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
gls{MFCC}
\end_layout

\end_inset

 for the fricative sound, due to the similarity of the phoneme acoustics
 of the two.
 This means that usually a couple of phoneme models (ç and e in this example)
 are assigned falsely to the regions of the inter-word silence, which is
 extended in longer time than it should be.
 Sometimes instead of being delayed, the 
\emph on
sp 
\emph default
model is prematurely 'jumped to' due to the same type of fricative confusion.
 In contrast, when leaks of accompaniment sounds are present, the added
 ACC model helps in distinguishing between the fricative and silence/ACC.
 
\end_layout

\begin_layout Section
Training the acoustic model
\begin_inset CommandInset label
LatexCommand label
name "sec:Training-the-acoustic"

\end_inset


\end_layout

\begin_layout Standard

\color black
To represent the 
\emph on
acoustic model 
\emph default
(also known as the phonetic model) 
\begin_inset Formula $P(y_{k}|x_{k})$
\end_inset

 of observing the 
\color inherit

\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
gls{MFCC}
\end_layout

\end_inset


\color black
 feature vector 
\begin_inset Formula $y_{k}$
\end_inset

 at a time instant 
\begin_inset Formula $k$
\end_inset

, given a phoneme 
\begin_inset Formula $x_{k}$
\end_inset

, a classifier of the different phonemes is needed.
 In essence, for a phonetic recognizer a hidden variable is the current
 phoneme class 
\begin_inset Formula $x_{k}$
\end_inset

 (see Figure 
\begin_inset CommandInset ref
LatexCommand ref
reference "DBN_model"

\end_inset

).
 The phoneme classifier has to represent the acoustic specificities of the
 different phonemes.
 In this section we present how we trained 
\color inherit

\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
gls{GMM}
\end_layout

\end_inset


\color black
-s and 
\color inherit

\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
gls{MLP}
\end_layout

\end_inset


\color black
-s — two different types of classifiers.
 
\end_layout

\begin_layout Subsection
Gaussian mixture models
\end_layout

\begin_layout Standard

\color black
As presented in Section 
\color inherit

\begin_inset CommandInset ref
LatexCommand ref
reference "subsec:Phoneme-network"

\end_inset

 the 
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
gls{GMM}
\end_layout

\end_inset

-s until recently have been the
\emph on
 de facto
\emph default
 choice of phonetic timbre classifier.
 They have the ability, given enough mixtures, to approximate arbitrarily
 shaped densities.
 It is reasonable to assume that each mixture represents a broad class of
 a phonetic timbre event.
 Another reason to be preferred, is the so called 
\emph on
embedded reestimation
\emph default
 training technique.
 By means of it, it is relatively straightforward to train the model's parameter
s even from material with no phoneme annotations.
 Embedded reestimation is an generalization of the Expectation Maximization
 algorithm over time-series of feature vectors and has an efficient implementati
on in 
\emph on
htk
\emph default
 
\begin_inset CommandInset citation
LatexCommand citep
key "young1993htk"

\end_inset

.
 Utilizing 
\emph on
htk 
\emph default
we fitted a 9-component 
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
gls{GMM}
\end_layout

\end_inset

 for each phoneme on feature vectors extracted from a dataset of Turkish
 speech 
\begin_inset CommandInset citation
LatexCommand citep
key "Salor2007580"

\end_inset


\begin_inset Foot
status open

\begin_layout Plain Layout
Training script is available at 
\begin_inset CommandInset href
LatexCommand href
target "https://github.com/georgid/Lyrics2AudioAligner/tree/synthesis/TrainingStep"

\end_inset


\end_layout

\end_inset

.
 The dataset encompasses diverse speech recordings totaling to approximately
 500 minutes.
 Preliminary experiments confirmed that the trained models can successfully
 recognize withheld speech material from the same dataset
\begin_inset Note Note
status open

\begin_layout Plain Layout
here add graph of saturation.
 Maybe it is in the https://github.com/georgid/Lyrics2AudioAligner/tree/synthesis
/TrainingStep
\end_layout

\end_inset

.
\end_layout

\begin_layout Standard
To address the acoustic differences between speech and singing an adaptation
 of the trained 
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
gls{GMM}
\end_layout

\end_inset

-s to singing material is needed.
 However due to lack of sufficient adaptation material we did not perform
 any adaptation
\begin_inset Foot
status open

\begin_layout Plain Layout
Some scripts on preliminary adaptation experiments are available at 
\begin_inset CommandInset href
LatexCommand href
target "https://github.com/georgid/Lyrics2AudioAligner/tree/synthesis/AdaptationStep"

\end_inset


\end_layout

\end_inset

.
 Instead of that we explored the option of using neural networks for the
 acoustic model.
\end_layout

\begin_layout Subsection
Multilayer perceptron neural networks
\end_layout

\begin_layout Standard
Recent work on keyword spotting in English 
\emph on
a cappella
\emph default
 singing showed that a 
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
gls{MLP}
\end_layout

\end_inset

 trained on singing-like material results in much better accuracy, compared
 to a 
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
gls{GMM}
\end_layout

\end_inset

, trained on speech 
\begin_inset CommandInset citation
LatexCommand citet
key "kruspe2015training"

\end_inset

.
\end_layout

\begin_layout Standard
This motivated us to take the opportunity to consider the deep 
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
gls{MLP}
\end_layout

\end_inset

 model the authors trained from amateur singers in their subsequent work
 — 
\begin_inset CommandInset citation
LatexCommand citep
key "kruspe2016bootstrapping"

\end_inset

.
 We introduced their training procedure in Section 
\begin_inset CommandInset ref
LatexCommand ref
reference "par:Training-on-singing"

\end_inset

 and will refer to their model as
\emph on
 MLP-English.

\emph default
 The 
\emph on
MLP-English
\emph default
 has 3 hidden layers with sigmoid activation function.
 The layers have respectively 1024, 850 and 1024 neurons and have as input
 the first 13 
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
gls{MFCC}
\end_layout

\end_inset

, extracted with the 
\emph on
htk
\emph default
 extraction parameters, described in 
\begin_inset CommandInset ref
LatexCommand ref
reference "subsec:Features"

\end_inset

 plus their deltas and accelerations.
 This results in a 39-dimensional feature vector.
 The phonetic alphabet used is the English-specific encoding of IPA from
 Carnegie Mellon University (CMU)
\begin_inset Foot
status collapsed

\begin_layout Plain Layout
\begin_inset CommandInset href
LatexCommand href
target "http://cmusphinx.sourceforge.net/"

\end_inset


\end_layout

\end_inset

.
\end_layout

\begin_layout Standard
Since we did not have as many Turkish singing voice phoneme annotations,
 sufficient for training a deep 
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
gls{MLP}
\end_layout

\end_inset

, we simply adapted the 
\emph on
MLP-English
\emph default
 to Turkish.
 We exploited two cross-language phoneme mapping strategies: direct mapping
 and fuzzy mapping
\end_layout

\begin_layout Subsubsection
Direct cross-language mapping
\begin_inset CommandInset label
LatexCommand label
name "subsec:Direct-cross-language-mapping"

\end_inset


\end_layout

\begin_layout Standard
As observation probability for each Turkish phoneme we substituted the probabili
ty of an English phoneme from the output layer of the 
\emph on
MLP-English
\emph default
.
 The mappings we used are listed in Table 
\begin_inset CommandInset ref
LatexCommand ref
reference "Phoneme-mappings"

\end_inset

.
 
\begin_inset Float table
wide false
sideways false
status collapsed

\begin_layout Plain Layout
\align center
\begin_inset Tabular
<lyxtabular version="3" rows="2" columns="13">
<features tabularvalignment="middle">
<column alignment="center" valignment="top">
<column alignment="center" valignment="top">
<column alignment="center" valignment="top">
<column alignment="center" valignment="top">
<column alignment="center" valignment="top">
<column alignment="center" valignment="top">
<column alignment="center" valignment="top">
<column alignment="center" valignment="top">
<column alignment="center" valignment="top">
<column alignment="center" valignment="top">
<column alignment="center" valignment="top">
<column alignment="center" valignment="top">
<column alignment="center" valignment="top">
<row>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
METUbet 
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
IY 
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
AA 
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
UE 
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
E 
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
LL 
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
I 
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
O 
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
M 
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
U 
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
OE 
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
NN
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\family roman
\series medium
\shape up
\size normal
\emph off
\bar no
\strikeout off
\uuline off
\uwave off
\noun off
\color none
VV
\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="center" valignment="top" topline="true" bottomline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
CMU 
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
iy 
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
aa 
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
y 
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
eh 
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
l 
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
ax 
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
ao 
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
m 
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
uw 
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
ow 
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
n
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\family roman
\series medium
\shape up
\size normal
\emph off
\bar no
\strikeout off
\uuline off
\uwave off
\noun off
\color none
v
\end_layout

\end_inset
</cell>
</row>
</lyxtabular>

\end_inset


\end_layout

\begin_layout Plain Layout
\align center
\begin_inset Tabular
<lyxtabular version="3" rows="2" columns="14">
<features tabularvalignment="middle">
<column alignment="center" valignment="top">
<column alignment="center" valignment="top">
<column alignment="center" valignment="top">
<column alignment="center" valignment="top">
<column alignment="center" valignment="top">
<column alignment="center" valignment="top">
<column alignment="center" valignment="top">
<column alignment="center" valignment="top">
<column alignment="center" valignment="top">
<column alignment="center" valignment="top">
<column alignment="center" valignment="top">
<column alignment="center" valignment="top">
<column alignment="center" valignment="top">
<column alignment="center" valignment="top">
<row>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
METUbet 
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Z 
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
C 
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
ZH 
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
H 
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
CH 
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
B 
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
D 
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
GG 
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
F 
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
KK 
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
P 
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
S 
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
RR 
\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="center" valignment="top" topline="true" bottomline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
CMU 
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
z 
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
jh 
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
zh 
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
hh 
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
ch 
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
b 
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
d 
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
g 
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
f 
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
k 
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
p 
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
s 
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
r 
\end_layout

\end_inset
</cell>
</row>
</lyxtabular>

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption Standard

\begin_layout Plain Layout
Direct mapping of English CMU phonemes to Turkish METUbet.
 Upper row vowels and liquids.
 Lower row all the rest consonants.
 
\end_layout

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset CommandInset label
LatexCommand label
name "Phoneme-mappings"

\end_inset

 
\end_layout

\end_inset


\end_layout

\begin_layout Standard
To most phonemes in Turkish corresponds an English phoneme that represents
 a sound with perceivably the same acoustics.
 The only two Turkish phonemes not existing in English are OE and UE, for
 which we experimented with different mappings and ended up with respectively
 
\emph on
ow 
\emph default
and 
\emph on
y
\emph default
 as most optimal.
 We will refer to this mapping strategy as 
\emph on
MLP-DirectM
\emph default
.
 
\end_layout

\begin_layout Subsubsection
Fuzzy cross-language mapping
\end_layout

\begin_layout Standard
A more reasonable alternative to enforcing a phoneme to be represented by
 exactly one phoneme from another language is a weighted sum of the acoustics
 of a set of similar phonemes.
 Such types of 'fuzzy' many-to-one mapping strategy has been proposed for
 speech synthesis of a given speaker from her mother tongue to another language
 by 
\begin_inset CommandInset citation
LatexCommand citet
key "sun2016personalized"

\end_inset

.
 Adopting the core idea of their concept, we trained 
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
gls{GMM}
\end_layout

\end_inset

-s with the steps presented in Figure 
\begin_inset CommandInset ref
LatexCommand ref
reference "cross-language strategy"

\end_inset

.
 First the extracted 
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
gls{MFCC}
\end_layout

\end_inset

 features from the 
\emph on
a cappella lyrics OTMM dataset
\emph default
 are input to the 
\emph on
English-MLP.

\emph default
 Then a vector of the posterior probabilities 
\begin_inset Formula $p(s_{n}|x_{k})$
\end_inset

 of the 
\begin_inset Formula $n=39$
\end_inset

 English phoneme classes for each time frame 
\begin_inset Formula $k$
\end_inset

 are generated (see the left hand-side of Figure 
\begin_inset CommandInset ref
LatexCommand ref
reference "cross-language strategy"

\end_inset

).
 These phonetic posterior probabilities are commonly known as phonetic posteriog
rams (PPG).
 Then in a second stage, a new model is trained to capture the mapping relations
hips between the posteriograms 
\begin_inset Formula $p(s_{n}|x_{k})$
\end_inset

 and the 38 Turkish phoneme classes.
 The PPGs are fed into the classifier as if they were the acoustic feature
 vectors.
 While 
\begin_inset CommandInset citation
LatexCommand citet
key "sun2016personalized"

\end_inset

 built another deep neural network, we preferred a 2-component 
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
gls{GMM}
\end_layout

\end_inset

 classifier, because training material with data sizes as small as 30 minutes
 of phoneme-annotated singing is usually enough for a GMM.
 Note that one could have trained 
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
gls{GMM}
\end_layout

\end_inset

-s by embedded re-estimation to avoid the need of phoneme boundary annotations.
 However, we preferred training on annotations to ensure appropriate mappings
 between the acoustics of the two languages.
 Then on recognition the English PPGs are generated in the same way as on
 training.
 Training was conducted with leave-one-recording-out cross validation.
 We will refer to this mapping strategy as 
\emph on
MLP-FuzzyM
\emph default

\begin_inset Foot
status open

\begin_layout Plain Layout
Data preparation script available at 
\begin_inset CommandInset href
LatexCommand href
target "https://github.com/georgid/englishMLP2turkish"

\end_inset


\end_layout

\end_inset

.
 
\end_layout

\begin_layout Standard
\begin_inset Float figure
wide false
sideways false
status open

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename Phd_Figs/baseline/cross-language-mapping.png
	lyxscale 20
	scale 40

\end_inset

 
\end_layout

\begin_layout Plain Layout
\begin_inset Caption Standard

\begin_layout Plain Layout
Cross-language phoneme mapping strategy from the source language (English)
 to the target language (Turkish).
 The 
\emph on
English-MLP
\emph default
 network is trained on a huge 
\emph on
DAMP
\emph default
 singing voice dataset, whereas the 
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
gls{GMM}
\end_layout

\end_inset

-s are trained with phoneme annotations of a subset of the small 
\emph on
a cappella lyrics OTMM dataset
\emph default
.
 
\end_layout

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset CommandInset label
LatexCommand label
name "cross-language strategy"

\end_inset

 
\end_layout

\end_inset


\end_layout

\begin_layout Standard
\begin_inset VSpace medskip
\end_inset


\end_layout

\begin_layout Standard
We compared the two mapping strategies with the baseline 
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
gls{GMM}
\end_layout

\end_inset

-s trained with Turkish speech.
 We evaluated the percent of correct frames.
 To generate binary phoneme activations, we set to 1 the phonemes with maximum
 posterior probability for each time frame and zero to the rest of the phonemes.
 Then this sparse activation matrix is intersected with an oracle matrix,
 inferred from manually annotated phoneme boundaries.
 The first two models were evaluated on the whole phoneme-annotated subset
 of the 
\emph on
a cappella lyrics OTMM dataset, 
\emph default
whereas the
\emph on
 MLP-FuzzyM
\emph default
 in the leave-one-out cross validation manner.
\begin_inset Note Note
status open

\begin_layout Plain Layout
INVENTED.
 Tried only on a couple of recordings 
\end_layout

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Float table
wide false
sideways false
status collapsed

\begin_layout Plain Layout
\align center
\begin_inset Tabular
<lyxtabular version="3" rows="4" columns="2">
<features tabularvalignment="middle">
<column alignment="center" valignment="top">
<column alignment="center" valignment="top">
<row>
<cell alignment="center" valignment="top" topline="true" bottomline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
model 
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
% correct frames
\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
GMM 
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
9.8
\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
MLP-DirectM 
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
15.4
\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="center" valignment="top" topline="true" bottomline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
MLP-FuzzyM 
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
9.2
\end_layout

\end_inset
</cell>
</row>
</lyxtabular>

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption Standard

\begin_layout Plain Layout
Percentage of correctly identified phoneme frames for the 3 different phoneme
 models utilized: 
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
gls{GMM}
\end_layout

\end_inset

 trained from Turkish speech, 
\emph on
MLP-English
\emph default
 model mapped directly to Turkish phonemes, 
\emph on
MLP-English
\emph default
 model mapped by the proposed fuzzy phoneme mapping strategy.
 
\end_layout

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset CommandInset label
LatexCommand label
name "fuzzy_evaluation"

\end_inset

 
\end_layout

\end_inset


\end_layout

\begin_layout Standard
Table 
\begin_inset CommandInset ref
LatexCommand ref
reference "fuzzy_evaluation"

\end_inset

 present the percentage of correctly detected frames compared to the phoneme
 annotations — a metric used for the first time by 
\begin_inset CommandInset citation
LatexCommand citet
key "kruspe2015training"

\end_inset


\begin_inset Foot
status collapsed

\begin_layout Plain Layout
We implemented the percentage of phoneme frames in a script available at
 
\begin_inset CommandInset href
LatexCommand href
target "https://github.com/georgid/AlignmentEvaluation/blob/master/align_eval/evalPhonemes.py"

\end_inset


\end_layout

\end_inset

.
 The 
\emph on
MLP-directM 
\emph default
evidences a major improvement over the 
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
gls{GMM}
\end_layout

\end_inset

-s trained on speech.
 It still scores reasonably worse than the reported 23 % in 
\begin_inset CommandInset citation
LatexCommand citet
key "kruspe2016bootstrapping"

\end_inset

 on excerpts from the same English dataset, with which it was trained.
 This large margin indicates that the direct mapping strategy may not be
 the optimal one.
 Surprisingly, the fuzzy mapping strategy did not yield improvement over
 the baseline mixture model.
 We believe that the explanation lies in the very small size of the training
 singing dataset with phoneme annotations.
 We attribute the remarkable improvement of the English-to-Turkish directly
 mapped model to the big learning capacity of a deep feedforward neural
 network.
\end_layout

\begin_layout Section
Experiments
\begin_inset CommandInset label
LatexCommand label
name "sec:Evaluation"

\end_inset


\end_layout

\begin_layout Standard
Experiments are carried out on the 
\emph on
a cappella lyrics OTMM dataset
\emph default
 (Section 
\begin_inset CommandInset ref
LatexCommand ref
reference "subsec:A-cappella-lyrics-1"

\end_inset

) and the 
\emph on
multi-instrumental lyrics OTMM dataset
\emph default
 (Section 
\begin_inset CommandInset ref
LatexCommand ref
reference "subsec:Accompanied-vocal-OTMM"

\end_inset

).
 To assess the effectiveness of the accompaniment attenuation (AA) step,
 we aligned the multi-instrumental recordings from the 
\emph on
a cappella lyrics OTMM dataset
\emph default
 with and without AA.
 In initial experiments we build a 
\emph on
Python
\emph default
 wrapper around 
\emph on
htk
\emph default
 that has efficient Viterbi decoding
\begin_inset Foot
status open

\begin_layout Plain Layout
\begin_inset CommandInset href
LatexCommand href
name "https://github.com/georgid/Lyrics2AudioAligner/tree/synthesis/AlignmentStep"
target "https://github.com/georgid/Lyrics2AudioAligner/tree/synthesis/AlignmentStep"

\end_inset


\end_layout

\end_inset

.
 To assure the same parameter setting of the baseline and the models that
 are aware of complementary context, we preferred to implement a custom
 
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
gls{HMM}
\end_layout

\end_inset

 and Viterbi decoding
\begin_inset Foot
status collapsed

\begin_layout Plain Layout
It is available as part of the repository 
\begin_inset CommandInset href
LatexCommand href
name "https://github.com/georgid/AlignmentDuration"
target "https://github.com/georgid/AlignmentDuration"

\end_inset

 by setting the parameter 
\emph on
WITH_DURATIONS
\emph default
 to 0.
 This repository has adopted some classes and Viterbi decoding logic from
 
\begin_inset CommandInset href
LatexCommand href
name "https://github.com/guyz/HMM"
target "https://github.com/guyz/HMM"

\end_inset


\end_layout

\end_inset

.
 The results reported are run with the latter implementation.
 We make available the source code of all experiments in this dissertation
 with the intention to serve as the first fully reproducible system for
 
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
gls{LAA}
\end_layout

\end_inset

.
 In addition, we hope this will encourage future research not only on 
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
gls{LAA}
\end_layout

\end_inset

, but also on related computational topics of lyrics tracking.
 
\end_layout

\begin_layout Standard
When accompanying instruments are present, we employed the modified phoneme
 network, which can handle possible artifacts from the AA step (see Section
 
\begin_inset CommandInset ref
LatexCommand ref
reference "subsec:Handling-accompaniment-artifacts"

\end_inset

).
\end_layout

\begin_layout Subsection
Evaluation metrics
\end_layout

\begin_layout Standard
Throughout this thesis, we evaluate the 
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
gls{LAA}
\end_layout

\end_inset

 by the metrics 
\emph on
average absolute error
\emph default
 and 
\emph on
accuracy (percentage of correct segments
\emph default
), introduced in Section 
\begin_inset CommandInset ref
LatexCommand ref
reference "subsec:Evaluation-metrics"

\end_inset

.
 We implemented a script for both metrics
\begin_inset Foot
status collapsed

\begin_layout Plain Layout
\begin_inset CommandInset href
LatexCommand href
name "https://github.com/georgid/AlignmentEvaluation"
target "https://github.com/georgid/AlignmentEvaluation"

\end_inset

 The implementation of the 
\emph on
percentage of correct segments
\emph default
 metric was ported from the script, kindly provided by H.
 Fujihara used in his work 
\begin_inset CommandInset citation
LatexCommand citet
key "fujihara2011lyricsynchronizer"

\end_inset


\end_layout

\end_inset

, which we plan to contribute to the collection of evaluation scripts of
 
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
gls{MIR}
\end_layout

\end_inset

 research 
\emph on
mir_eval
\emph default

\begin_inset Foot
status open

\begin_layout Plain Layout
\begin_inset CommandInset href
LatexCommand href
target "https://craffel.github.io/mir_eval/"

\end_inset


\end_layout

\end_inset

.
 The alignment error and accuracy are computed at boundaries of the lyrics
 phrases, which are manually annotated.
 
\end_layout

\begin_layout Standard
\begin_inset Float table
placement h
wide false
sideways false
status open

\begin_layout Plain Layout
\noindent
\align center
\begin_inset Tabular
<lyxtabular version="3" rows="8" columns="6">
<features booktabs="true" tabularvalignment="middle">
<column alignment="center" valignment="top">
<column alignment="center" valignment="top">
<column alignment="center" valignment="top">
<column alignment="center" valignment="top">
<column alignment="center" valignment="top">
<column alignment="center" valignment="top">
<row>
<cell alignment="center" valignment="top" topline="true" bottomline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
acoustic model
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
data
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
AA
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
AH
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
accuracy 
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
error
\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
GMMs
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
a cappella OTMM
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
-
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
-
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
70.2 
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
1.14
\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
MLP-DirectM
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
a cappella OTMM
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
-
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
-
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
79.2 
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
0.57
\begin_inset Note Note
status open

\begin_layout Plain Layout
invented
\end_layout

\end_inset


\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
GMMs
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
multi-instrumental OTMM
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
N
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
-
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
59.1
\begin_inset Note Note
status open

\begin_layout Plain Layout
invented
\end_layout

\end_inset


\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
2.15
\begin_inset Note Note
status open

\begin_layout Plain Layout
invented
\end_layout

\end_inset


\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
GMMs
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
multi-instrumental OTMM
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Y
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
N
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
63.2
\begin_inset Note Note
status open

\begin_layout Plain Layout
invented
\end_layout

\end_inset


\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
1.98
\begin_inset Note Note
status open

\begin_layout Plain Layout
invented
\end_layout

\end_inset


\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="center" valignment="top" topline="true" bottomline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
GMMs
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
multi-instrumental OTMM
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Y
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Y
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
67.5 
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
1.26
\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\family roman
\series medium
\shape up
\size normal
\emph off
\bar no
\strikeout off
\uuline off
\uwave off
\noun off
\color none
Mesaros
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
multi-instrumental English
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
-
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
-
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\family roman
\series medium
\shape up
\size normal
\emph off
\bar no
\strikeout off
\uuline off
\uwave off
\noun off
\color none
-
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\family roman
\series medium
\shape up
\size normal
\emph off
\bar no
\strikeout off
\uuline off
\uwave off
\noun off
\color none
1.4
\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="center" valignment="top" topline="true" bottomline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Fujihara
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
multi-instrumental Japanese
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
-
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
-
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\family roman
\series medium
\shape up
\size normal
\emph off
\bar no
\strikeout off
\uuline off
\uwave off
\noun off
\color none
85.2
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\family roman
\series medium
\shape up
\size normal
\emph off
\bar no
\strikeout off
\uuline off
\uwave off
\noun off
\color none
-
\end_layout

\end_inset
</cell>
</row>
</lyxtabular>

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption Standard

\begin_layout Plain Layout
Comparison of performance of the baseline phonetic recognizer with different
 variants of the acoustic model.
  Evaluation is performed on both 
\emph on
a cappella
\emph default
 and accompanied singing from 
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
gls{OTMM}
\end_layout

\end_inset

.
 Alignment accuracy and alignment error on the boundaries of lyrics phrases
 and reported on total for all recordings.
 Mesaros stands for the approach of 
\family roman
\series medium
\shape up
\size normal
\emph off
\bar no
\strikeout off
\uuline off
\uwave off
\noun off
\color none

\begin_inset CommandInset citation
LatexCommand citet
key "mesaros2008automatic"

\end_inset

; Fujihara for the approach of 
\begin_inset CommandInset citation
LatexCommand citet
key "fujihara2011lyricsynchronizer"

\end_inset

.
 
\family default
\series default
\shape default
\size default
\emph default
\bar default
\strikeout default
\uuline default
\uwave default
\noun default
\color inherit
AH stands for handling accompaniment artifacts (see Section 
\begin_inset CommandInset ref
LatexCommand ref
reference "subsec:Handling-accompaniment-artifacts"

\end_inset

).
\end_layout

\end_inset


\begin_inset CommandInset label
LatexCommand label
name "results baseline"

\end_inset

 
\end_layout

\end_inset


\end_layout

\begin_layout Standard
\begin_inset VSpace medskip
\end_inset


\end_layout

\begin_layout Subsection
Discussion
\end_layout

\begin_layout Standard
Table 
\begin_inset CommandInset ref
LatexCommand ref
reference "results baseline"

\end_inset

 lists results for the different system variants and steps of the recognizer.
 We compared the performance of the baseline phonetic recognizer on 
\emph on
a cappella
\emph default
 singing with two different variants of the acoustic model: with phoneme
 
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
gls{GMM}
\end_layout

\end_inset

-s and 
\emph on
MLP-directM
\emph default
 (the direct mapping to English-phonemes 
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
gls{MLP}
\end_layout

\end_inset

).
 The GMMs result in rather low accuracy.
 The most possible explanation is the acoustic mismatch between our  phoneme
 GMMs and the characteristics of singing voice.
 This is confirmed by the rather low results on 
\emph on
a cappella
\emph default
 singing.
 Training phoneme acoustics merely on speech is clearly suboptimal.
 The high score of the 
\emph on
MLP-DirectM
\emph default
 confirms that training on singing voice is a big advantage.
 
\end_layout

\begin_layout Standard
As to multi-instrumental material, adding the accompaniment attenuation
 improves reasonably accuracy (from 59.1 to 67.5 %).
 However still below the 
\emph on
a cappella
\emph default
 (70.2) clearly there is still room for improvement.
 In fact, investigating particular recording excerpts with low accuracy
 revealed that false positives of the AA module is a considerable reason
 for misalignment.
 We realize that the harmonic model (a generic model of singing voice) may
 not be the best choice for music with heterophonic character.
 
\begin_inset Note Note
status open

\begin_layout Plain Layout
FUTURE: song-wise errors are not well correlated.
 probable reason: different accuracy of vocal resynthesis? 
\end_layout

\end_inset


\end_layout

\begin_layout Standard
We observed that a problem is that alignment performs poorly towards the
 end of longer sections, which results in outliers of huge magnitude.
\end_layout

\begin_layout Standard
As a benchmark the best existing alignment systems for English pop songs
 
\begin_inset CommandInset citation
LatexCommand citep
key "mesaros2008automatic"

\end_inset

 and for Japanese pop 
\begin_inset CommandInset citation
LatexCommand citep
key "fujihara2011lyricsynchronizer"

\end_inset

 are listed in the table.
 Comparison to them is not possible because they are developed for different
 genre and language and evaluated on different datasets.
 These are short-named in Table 
\begin_inset CommandInset ref
LatexCommand ref
reference "results baseline"

\end_inset

 respectively as Mesaros and Fujihara.
 Still, in these works alignment is also evaluated with 
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
gls{GMM}
\end_layout

\end_inset

-s on the 
\color black
level of a lyrical line/phrase.

\color inherit
 Our baseline approach differs from both works essentially in that they
 conduct speech-to-singing-voice adaptation.
 In comparison, we did not perform any adaptation of the original speech
 model.
 Adaptation data of clean singing voice for a particular singer might not
 always be available and thus does not allow the system to scale to data
 from unknown singers.
 
\end_layout

\begin_layout Standard
Moreover, 
\begin_inset CommandInset citation
LatexCommand cite
key "fujihara2011lyricsynchronizer"

\end_inset

 trains a 
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
gls{VAD}
\end_layout

\end_inset

 module on data selected from material with same acoustic characteristics
 as the test data.
 The module showed to notably increase the average accuracy of 72.1 % for
 a baseline to accuracy of 85.2 % for their final system.
\series bold

\begin_inset Note Note
status open

\begin_layout Plain Layout
refine: 
\series bold
Similarly we observe that for our system evaluation on the acapella data
 yields an accuracy by about the same percent higher than the polyphonic
 one (see table 2).
\end_layout

\end_inset


\series default
 
\end_layout

\begin_layout Section
Summary
\end_layout

\begin_layout Standard
In this chapter we described our 
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
gls{LAA}
\end_layout

\end_inset

 baseline system.
 It is a phonetic recognizer, based on phoneme 
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
gls{HMM}
\end_layout

\end_inset

-s.
 We described the choices of the key steps of the phonetic recognizer, which
 are not related to modeling complementary context.
 Phoneme observation modeled as 
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
gls{GMM}
\end_layout

\end_inset

-s, trained on
\color black
 Turkish speech proved not to be the optimal acoustic model.
 The alignment accuracy on 
\emph on
a cappella
\emph default
 (70.2 %) is rather low; whereas on multi-instrumental recordings (67.5%)
 is below the state of the art on 
\color inherit

\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
gls{LAA}
\end_layout

\end_inset


\color black
 on English pop songs (85.2 %).
 
\color inherit
The most possible explanation is the acoustic mismatch between our  phoneme
 model and the characteristics of singing voice.
 To address this mismatch, we proposed
\series bold
 
\series default
a strategy of mapping a state-of-the-art model for English, trained on English
 pop songs, to Turkish.
 We explored two different mapping strategies.
 The simpler direct mapping increased reasonably the alignment accuracy
 (79.2 %).
 To our knowledge, this thesis presents the first work on computational
 modeling of sung lyrics, addressing the problem of inter-language phoneme
 mapping.
 
\end_layout

\begin_layout Standard

\color black
Despite its superiority, not all experiments (e.g.
 some presented in Chapter 4) are carried out with the phoneme 
\color inherit

\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
gls{GMM}
\end_layout

\end_inset


\color black
-s.
 This is because the mapping strategies were explored once the 
\emph on
English-MLP
\emph default
 became available (towards the end of this thesis
\begin_inset Foot
status open

\begin_layout Plain Layout

\color black
August 2016
\end_layout

\end_inset

).
 However, we believe that the validity of the experiments in this dissertation
 is not negatively influenced by that.
 
\end_layout

\end_body
\end_document

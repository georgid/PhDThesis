


@InProceedings{dzhambazov2016onsetLyrics_ismir,
  Title                    = {On the use of note onsets for improved lyrics-to-audio alignment in {T}urkish makam music},
  Author                   = {Dzhambazov, Georgi and Srinivasamurthy, Ajay and {\c S}en\-t{\"u}rk, Sertan and Serra, Xavier},
  Booktitle                = {{Proceedings of the 17th International Society for Music Information Retrieval Conference (ISMIR 2016)}},
  Year                     = {2016},

  Address                  = {New York, NY, USA},
  Pages                    = {716--722},

  Owner                    = {joro},
  Timestamp                = {2017.04.27},
  URL = {http://mtg.upf.edu/node/3492}
}


@conference {3565,
	title = {Singing Voice Separation by Harmonic Modeling},
	booktitle = { Music Information Retrieval Evaluation eXchange (MIREX)},
	year = {2016},
	author = {Georgi Dzhambazov and Xavier Serra},
	URL={http://mtg.upf.edu/node/3565}
}

@conference {3517,
	title = {Automatic Alignment of Long Syllables In A cappella Beijing Opera},
	booktitle = {Proceedings of 6th International Workshop on Folk Music Analysis (FMA 2016)},
	year = {2016},
	month = {15/06/2016},
	pages = {88-91},
	address = {Dublin, Ireland},
	abstract = {In this study we propose how to modify a standard approach for text-to-speech alignment to apply in the case of alignment of lyrics and singing voice. We model phoneme durations by means of a duration-explicit hidden Markov model (DHMM) phonetic recognizer based on MFCCs. The phoneme durations are empirically set in a probabilistic way, based on prior knowledge about the lyrics structure and metric principles, specific for the Beijing opera music tradition. Phoneme models are GMMs trained directly on a small corpus of annotated singing voice. The alignment is evaluated on a cappella material from Beijing opera, which is characterized by its particularly long syllable durations. Results show that the incorporation of music-specific knowledge results in a very high alignment accuracy, outperforming significantly a baseline HMM-based approach.},
	url = {http://mtg.upf.edu/node/3517},
	author = {Georgi Dzhambazov and Yile Yang and Rafael Caro Repetto and Xavier Serra}
}




@conference {3266,
	title = {Modeling of Phoneme Durations for Alignment between Polyphonic Audio and Lyrics},
	booktitle = {Sound and Music Computing Conference 2015},
	year = {2015},
	address = {Maynooth, Ireland},
	abstract = {In this work we propose how to modify a standard scheme for text-to-speech alignment for the alignment of lyrics and singing voice. To this end we model the duration of phonemes specific for the case of singing. We rely on a duration-explicit hidden Markov model (DHMM) phonetic recognizer based on mel frequency cepstral coefficients (MFCCs), which are extracted in a way robust to background instrumental sounds. The proposed approach is tested on polyphonic audio from the classical Turkish music tradition in two settings: with and without modeling phoneme durations. Phoneme durations are inferred from sheet music. In order to assess the impact of the polyphonic setting, alignment is evaluated as well on an acapella dataset, compiled especially for this study. We show that the explicit modeling of phoneme durations improves alignment accuracy by absolute 10 percent on the level of lyrics lines (phrases) and performs on par with state-of-the-art aligners for other languages.},
	author = {Georgi Dzhambazov and Xavier Serra},
	URL={http://mtg.upf.edu/node/3266}
}


@InProceedings{dzhambazov2014lyrics_fma,
  Title                    = {Automatic lyrics-to-audio alignment in classical {T}urkish music},
  Author                   = {Dzhambazov, Georgi and {\c{S}}ent{\"{u}}rk, Sertan and Serra, Xavier},
  Booktitle                = {{Proceedings of 4th International Workshop on Folk Music Analysis (FMA 2014)}},
  Year                     = {2014},

  Address                  = {Istanbul, Turkey},
  Pages                    = {61--64},

  Abstract                 = {We apply a lyrics-to-audio alignment state-of-the-art approach to polyphonic pieces from classical Turkish repertoire. A phonetic recognizer is employed, whereby each phoneme is assigned a hidden Markov model (HMM). Initially trained on speech, the models are adapted on singing voice to match the acoustic characteristics of the test dataset. Being the first study on lyrics-to-audio alignment applied on Turkish music, it could serve as a baseline for singing material with similar musical characteristics. As part of this work a dataset of recordings from the classical music tradition is compiled. Experiments, conducted separately for male and female singers, show that female singing is aligned more accurately.},
  File                     = {:publications/dzhambazov2014lyrics_fma.pdf:PDF},
  Keywords                 = {Turkish,Viterbi,alignment,hmm,lyrics,phonemes,singing voice},
  Owner                    = {joro},
  Timestamp                = {2017.04.27},
  URL={http://mtg.upf.edu/node/2965}
}


